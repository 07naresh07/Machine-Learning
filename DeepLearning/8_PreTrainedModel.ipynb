{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Loading libraries**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import shutil\n",
    "from PIL import Image\n",
    "import os"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Creating directories**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "base_dir = 'sample_data'\n",
    "class1_dir = os.path.join(base_dir, 'class1')\n",
    "class2_dir = os.path.join(base_dir, 'class2')\n",
    "os.makedirs(class1_dir, exist_ok=True)\n",
    "os.makedirs(class2_dir, exist_ok=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Generate and save random images**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sample images are generated at sample_data with 100 images per class.\n"
     ]
    }
   ],
   "source": [
    "def generate_random_images(save_dir, num_images):\n",
    "    for i in range(num_images):\n",
    "        img = Image.fromarray(np.uint8(np.random.rand(224, 224, 3)*255))\n",
    "        img.save(os.path.join(save_dir, f'image_{i}.jpg'))\n",
    "\n",
    "num_images_per_class = 100\n",
    "generate_random_images(class1_dir, num_images_per_class)\n",
    "generate_random_images(class2_dir, num_images_per_class)\n",
    "print(f'Sample images are generated at {base_dir} with {num_images_per_class} images per class.')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Load libraries for *pre-trained* models**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.applications import VGG16\n",
    "from tensorflow.keras.layers import Flatten, Dense\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "from tensorflow.keras.optimizers.legacy import Adam"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-05-21 22:51:36.685169: I metal_plugin/src/device/metal_device.cc:1154] Metal device set to: Apple M2\n",
      "2025-05-21 22:51:36.685196: I metal_plugin/src/device/metal_device.cc:296] systemMemory: 16.00 GB\n",
      "2025-05-21 22:51:36.685205: I metal_plugin/src/device/metal_device.cc:313] maxCacheSize: 5.33 GB\n",
      "2025-05-21 22:51:36.685244: I tensorflow/core/common_runtime/pluggable_device/pluggable_device_factory.cc:306] Could not identify NUMA node of platform GPU ID 0, defaulting to 0. Your kernel may not have been built with NUMA support.\n",
      "2025-05-21 22:51:36.685264: I tensorflow/core/common_runtime/pluggable_device/pluggable_device_factory.cc:272] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 0 MB memory) -> physical PluggableDevice (device: 0, name: METAL, pci bus id: <undefined>)\n"
     ]
    }
   ],
   "source": [
    "# Load VGG16 model pre-trained on imagenet\n",
    "base_model = VGG16(weights='imagenet',\n",
    "                   include_top=False,\n",
    "                   input_shape=(224, 224, 3))\n",
    "\n",
    "# Freeze all layers initially\n",
    "for layer in base_model.layers:\n",
    "    layer.trainable=False\n",
    "\n",
    "# Create new model and add base model and new layers\n",
    "model = Sequential([\n",
    "    base_model,\n",
    "    Flatten(),\n",
    "    Dense(256, activation='relu'),\n",
    "    Dense(1, activation='sigmoid')\n",
    "])\n",
    "\n",
    "# Compile the model\n",
    "model.compile(optimizer=Adam(learning_rate=0.001),\n",
    "              loss='binary_crossentropy',\n",
    "              metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Load and preprocess the data**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 200 images belonging to 2 classes.\n",
      "Epoch 1/10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-05-21 22:51:39.122944: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:117] Plugin optimizer for device_type GPU is enabled.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "7/7 [==============================] - 3s 314ms/step - loss: 3.7136 - accuracy: 0.5100\n",
      "Epoch 2/10\n",
      "7/7 [==============================] - 2s 308ms/step - loss: 6.0111 - accuracy: 0.5000\n",
      "Epoch 3/10\n",
      "7/7 [==============================] - 2s 308ms/step - loss: 3.1872 - accuracy: 0.5150\n",
      "Epoch 4/10\n",
      "7/7 [==============================] - 2s 308ms/step - loss: 1.8039 - accuracy: 0.5200\n",
      "Epoch 5/10\n",
      "7/7 [==============================] - 2s 311ms/step - loss: 1.3614 - accuracy: 0.5500\n",
      "Epoch 6/10\n",
      "7/7 [==============================] - 2s 308ms/step - loss: 1.1290 - accuracy: 0.5400\n",
      "Epoch 7/10\n",
      "7/7 [==============================] - 2s 308ms/step - loss: 0.8815 - accuracy: 0.5700\n",
      "Epoch 8/10\n",
      "7/7 [==============================] - 2s 308ms/step - loss: 0.7583 - accuracy: 0.5850\n",
      "Epoch 9/10\n",
      "7/7 [==============================] - 2s 308ms/step - loss: 0.7749 - accuracy: 0.5700\n",
      "Epoch 10/10\n",
      "7/7 [==============================] - 2s 308ms/step - loss: 0.7931 - accuracy: 0.5550\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.src.callbacks.History at 0x16d84d240>"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_datagen = ImageDataGenerator(rescale=1./255)\n",
    "train_generator = train_datagen.flow_from_directory('/Users/nareshdhami/Desktop/Visual Code/DeepLearning/sample_data',\n",
    "                                                    target_size=(224, 224),\n",
    "                                                    batch_size=32,\n",
    "                                                    class_mode='binary')\n",
    "\n",
    "# Train the model with frozen layers\n",
    "model.fit(train_generator, epochs=10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Lets gradually unfreeze the frozen layers**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "7/7 [==============================] - 4s 415ms/step - loss: 0.7608 - accuracy: 0.5400\n",
      "Epoch 2/10\n",
      "7/7 [==============================] - 3s 374ms/step - loss: 0.7520 - accuracy: 0.5500\n",
      "Epoch 3/10\n",
      "7/7 [==============================] - 3s 383ms/step - loss: 0.7498 - accuracy: 0.5600\n",
      "Epoch 4/10\n",
      "7/7 [==============================] - 3s 379ms/step - loss: 0.7462 - accuracy: 0.5500\n",
      "Epoch 5/10\n",
      "7/7 [==============================] - 3s 429ms/step - loss: 0.7493 - accuracy: 0.5600\n",
      "Epoch 6/10\n",
      "7/7 [==============================] - 3s 378ms/step - loss: 0.7481 - accuracy: 0.5400\n",
      "Epoch 7/10\n",
      "7/7 [==============================] - 3s 378ms/step - loss: 0.7466 - accuracy: 0.5450\n",
      "Epoch 8/10\n",
      "7/7 [==============================] - 3s 377ms/step - loss: 0.7460 - accuracy: 0.5500\n",
      "Epoch 9/10\n",
      "7/7 [==============================] - 3s 377ms/step - loss: 0.7480 - accuracy: 0.5400\n",
      "Epoch 10/10\n",
      "7/7 [==============================] - 3s 378ms/step - loss: 0.7461 - accuracy: 0.5450\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.src.callbacks.History at 0x1756853f0>"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "for layer in base_model.layers[-4:]:    # Unfreeze last 4 layers\n",
    "    layer.trainable = True\n",
    "\n",
    "# Compile model again with lower learning rate\n",
    "model.compile(optimizer=Adam(learning_rate=0.0001),\n",
    "              loss='binary_crossentropy',\n",
    "              metrics=['accuracy'])\n",
    "model.fit(train_generator, epochs=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **To work with TensorFlow-CPU**\n",
    "import os</br>\n",
    "os.environ['TF_ENABLE_ONEDNN_OPTS'] = '0'</br>\n",
    "os.environ['TF_CPP_MIN_LOG_LEVEL'] = '2'</br>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Import Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import keras\n",
    "\n",
    "import warnings\n",
    "warnings.simplefilter('ignore', FutureWarning)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Dataset**\n",
    "\n",
    "<strong>The dataset is about the compressive strength of different samples of concrete based on the volumes of the different ingredients that were used to make them. Ingredients include:</strong>\n",
    "\n",
    "* Cement\n",
    "* Blast furnace slag\n",
    "* Fly ash\n",
    "* Water\n",
    "* Superplasticizer\n",
    "* Coarse aggregate\n",
    "* Fine aggregate"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Loading Datasets**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Cement</th>\n",
       "      <th>Blast Furnace Slag</th>\n",
       "      <th>Fly Ash</th>\n",
       "      <th>Water</th>\n",
       "      <th>Superplasticizer</th>\n",
       "      <th>Coarse Aggregate</th>\n",
       "      <th>Fine Aggregate</th>\n",
       "      <th>Age</th>\n",
       "      <th>Strength</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>540.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>162.0</td>\n",
       "      <td>2.5</td>\n",
       "      <td>1040.0</td>\n",
       "      <td>676.0</td>\n",
       "      <td>28</td>\n",
       "      <td>79.99</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>540.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>162.0</td>\n",
       "      <td>2.5</td>\n",
       "      <td>1055.0</td>\n",
       "      <td>676.0</td>\n",
       "      <td>28</td>\n",
       "      <td>61.89</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>332.5</td>\n",
       "      <td>142.5</td>\n",
       "      <td>0.0</td>\n",
       "      <td>228.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>932.0</td>\n",
       "      <td>594.0</td>\n",
       "      <td>270</td>\n",
       "      <td>40.27</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>332.5</td>\n",
       "      <td>142.5</td>\n",
       "      <td>0.0</td>\n",
       "      <td>228.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>932.0</td>\n",
       "      <td>594.0</td>\n",
       "      <td>365</td>\n",
       "      <td>41.05</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>198.6</td>\n",
       "      <td>132.4</td>\n",
       "      <td>0.0</td>\n",
       "      <td>192.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>978.4</td>\n",
       "      <td>825.5</td>\n",
       "      <td>360</td>\n",
       "      <td>44.30</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Cement  Blast Furnace Slag  Fly Ash  Water  Superplasticizer  \\\n",
       "0   540.0                 0.0      0.0  162.0               2.5   \n",
       "1   540.0                 0.0      0.0  162.0               2.5   \n",
       "2   332.5               142.5      0.0  228.0               0.0   \n",
       "3   332.5               142.5      0.0  228.0               0.0   \n",
       "4   198.6               132.4      0.0  192.0               0.0   \n",
       "\n",
       "   Coarse Aggregate  Fine Aggregate  Age  Strength  \n",
       "0            1040.0           676.0   28     79.99  \n",
       "1            1055.0           676.0   28     61.89  \n",
       "2             932.0           594.0  270     40.27  \n",
       "3             932.0           594.0  365     41.05  \n",
       "4             978.4           825.5  360     44.30  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "url = 'https://s3-api.us-geo.objectstorage.softlayer.net/cf-courses-data/CognitiveClass/DL0101EN/labs/data/concrete_data.csv'\n",
    "df = pd.read_csv(url)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "So the first concrete sample has 540 cubic meter of cement, 0 cubic meter of blast furnace slag, 0 cubic meter of fly ash, 162 cubic meter of water, 2.5 cubic meter of superplaticizer, 1040 cubic meter of coarse aggregate, 676 cubic meter of fine aggregate. Such a concrete mix which is 28 days old, has a compressive strength of 79.99 MPa. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Lets check the shpae of the data**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1030, 9)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "So, there are approximately 1000 samples to train our model on. Because of the few samples, we have to be careful not to overfit the training data.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Lets check for any missing value**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Cement                0\n",
       "Blast Furnace Slag    0\n",
       "Fly Ash               0\n",
       "Water                 0\n",
       "Superplasticizer      0\n",
       "Coarse Aggregate      0\n",
       "Fine Aggregate        0\n",
       "Age                   0\n",
       "Strength              0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Cement</th>\n",
       "      <th>Blast Furnace Slag</th>\n",
       "      <th>Fly Ash</th>\n",
       "      <th>Water</th>\n",
       "      <th>Superplasticizer</th>\n",
       "      <th>Coarse Aggregate</th>\n",
       "      <th>Fine Aggregate</th>\n",
       "      <th>Age</th>\n",
       "      <th>Strength</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>1030.000000</td>\n",
       "      <td>1030.000000</td>\n",
       "      <td>1030.000000</td>\n",
       "      <td>1030.000000</td>\n",
       "      <td>1030.000000</td>\n",
       "      <td>1030.000000</td>\n",
       "      <td>1030.000000</td>\n",
       "      <td>1030.000000</td>\n",
       "      <td>1030.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>281.167864</td>\n",
       "      <td>73.895825</td>\n",
       "      <td>54.188350</td>\n",
       "      <td>181.567282</td>\n",
       "      <td>6.204660</td>\n",
       "      <td>972.918932</td>\n",
       "      <td>773.580485</td>\n",
       "      <td>45.662136</td>\n",
       "      <td>35.817961</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>104.506364</td>\n",
       "      <td>86.279342</td>\n",
       "      <td>63.997004</td>\n",
       "      <td>21.354219</td>\n",
       "      <td>5.973841</td>\n",
       "      <td>77.753954</td>\n",
       "      <td>80.175980</td>\n",
       "      <td>63.169912</td>\n",
       "      <td>16.705742</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>102.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>121.800000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>801.000000</td>\n",
       "      <td>594.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>2.330000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>192.375000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>164.900000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>932.000000</td>\n",
       "      <td>730.950000</td>\n",
       "      <td>7.000000</td>\n",
       "      <td>23.710000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>272.900000</td>\n",
       "      <td>22.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>185.000000</td>\n",
       "      <td>6.400000</td>\n",
       "      <td>968.000000</td>\n",
       "      <td>779.500000</td>\n",
       "      <td>28.000000</td>\n",
       "      <td>34.445000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>350.000000</td>\n",
       "      <td>142.950000</td>\n",
       "      <td>118.300000</td>\n",
       "      <td>192.000000</td>\n",
       "      <td>10.200000</td>\n",
       "      <td>1029.400000</td>\n",
       "      <td>824.000000</td>\n",
       "      <td>56.000000</td>\n",
       "      <td>46.135000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>540.000000</td>\n",
       "      <td>359.400000</td>\n",
       "      <td>200.100000</td>\n",
       "      <td>247.000000</td>\n",
       "      <td>32.200000</td>\n",
       "      <td>1145.000000</td>\n",
       "      <td>992.600000</td>\n",
       "      <td>365.000000</td>\n",
       "      <td>82.600000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            Cement  Blast Furnace Slag      Fly Ash        Water  \\\n",
       "count  1030.000000         1030.000000  1030.000000  1030.000000   \n",
       "mean    281.167864           73.895825    54.188350   181.567282   \n",
       "std     104.506364           86.279342    63.997004    21.354219   \n",
       "min     102.000000            0.000000     0.000000   121.800000   \n",
       "25%     192.375000            0.000000     0.000000   164.900000   \n",
       "50%     272.900000           22.000000     0.000000   185.000000   \n",
       "75%     350.000000          142.950000   118.300000   192.000000   \n",
       "max     540.000000          359.400000   200.100000   247.000000   \n",
       "\n",
       "       Superplasticizer  Coarse Aggregate  Fine Aggregate          Age  \\\n",
       "count       1030.000000       1030.000000     1030.000000  1030.000000   \n",
       "mean           6.204660        972.918932      773.580485    45.662136   \n",
       "std            5.973841         77.753954       80.175980    63.169912   \n",
       "min            0.000000        801.000000      594.000000     1.000000   \n",
       "25%            0.000000        932.000000      730.950000     7.000000   \n",
       "50%            6.400000        968.000000      779.500000    28.000000   \n",
       "75%           10.200000       1029.400000      824.000000    56.000000   \n",
       "max           32.200000       1145.000000      992.600000   365.000000   \n",
       "\n",
       "          Strength  \n",
       "count  1030.000000  \n",
       "mean     35.817961  \n",
       "std      16.705742  \n",
       "min       2.330000  \n",
       "25%      23.710000  \n",
       "50%      34.445000  \n",
       "75%      46.135000  \n",
       "max      82.600000  "
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Lets split the dataset into predictors and target**\n",
    "\n",
    "Predictors: All columns other than the target column i.e. except predicting column</br>\n",
    "Target: Column to be predicted"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "concrete_data_columns = df.columns\n",
    "predictors = df[concrete_data_columns[concrete_data_columns!='Strength']]\n",
    "target = df.Strength"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We have our predictor and target DataFrame."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   Cement  Blast Furnace Slag  Fly Ash  Water  Superplasticizer  \\\n",
      "0   540.0                 0.0      0.0  162.0               2.5   \n",
      "1   540.0                 0.0      0.0  162.0               2.5   \n",
      "2   332.5               142.5      0.0  228.0               0.0   \n",
      "3   332.5               142.5      0.0  228.0               0.0   \n",
      "4   198.6               132.4      0.0  192.0               0.0   \n",
      "\n",
      "   Coarse Aggregate  Fine Aggregate  Age  \n",
      "0            1040.0           676.0   28  \n",
      "1            1055.0           676.0   28  \n",
      "2             932.0           594.0  270  \n",
      "3             932.0           594.0  365  \n",
      "4             978.4           825.5  360  \n",
      "0    79.99\n",
      "1    61.89\n",
      "2    40.27\n",
      "3    41.05\n",
      "4    44.30\n",
      "Name: Strength, dtype: float64\n"
     ]
    }
   ],
   "source": [
    "print(predictors.head())\n",
    "print(target.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Finally, the last step is to normalize the data by substracting the mean and dividing by the standard deviation.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Cement</th>\n",
       "      <th>Blast Furnace Slag</th>\n",
       "      <th>Fly Ash</th>\n",
       "      <th>Water</th>\n",
       "      <th>Superplasticizer</th>\n",
       "      <th>Coarse Aggregate</th>\n",
       "      <th>Fine Aggregate</th>\n",
       "      <th>Age</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>288</th>\n",
       "      <td>-0.954658</td>\n",
       "      <td>-0.856472</td>\n",
       "      <td>1.762765</td>\n",
       "      <td>-0.560418</td>\n",
       "      <td>0.233575</td>\n",
       "      <td>1.063368</td>\n",
       "      <td>0.052628</td>\n",
       "      <td>0.860186</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1024</th>\n",
       "      <td>-1.102018</td>\n",
       "      <td>2.153519</td>\n",
       "      <td>-0.846733</td>\n",
       "      <td>0.076459</td>\n",
       "      <td>1.087297</td>\n",
       "      <td>-1.467693</td>\n",
       "      <td>0.663784</td>\n",
       "      <td>-0.279597</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>80</th>\n",
       "      <td>1.376300</td>\n",
       "      <td>0.375573</td>\n",
       "      <td>-0.846733</td>\n",
       "      <td>-1.314367</td>\n",
       "      <td>1.723404</td>\n",
       "      <td>-1.553862</td>\n",
       "      <td>1.415879</td>\n",
       "      <td>-0.675355</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>320</th>\n",
       "      <td>-0.306851</td>\n",
       "      <td>-0.856472</td>\n",
       "      <td>0.697090</td>\n",
       "      <td>-1.098953</td>\n",
       "      <td>1.104037</td>\n",
       "      <td>0.191387</td>\n",
       "      <td>1.439577</td>\n",
       "      <td>-0.501222</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>538</th>\n",
       "      <td>1.902584</td>\n",
       "      <td>-0.856472</td>\n",
       "      <td>-0.846733</td>\n",
       "      <td>0.488555</td>\n",
       "      <td>-1.038638</td>\n",
       "      <td>-0.472245</td>\n",
       "      <td>-0.765572</td>\n",
       "      <td>-0.612034</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        Cement  Blast Furnace Slag   Fly Ash     Water  Superplasticizer  \\\n",
       "288  -0.954658           -0.856472  1.762765 -0.560418          0.233575   \n",
       "1024 -1.102018            2.153519 -0.846733  0.076459          1.087297   \n",
       "80    1.376300            0.375573 -0.846733 -1.314367          1.723404   \n",
       "320  -0.306851           -0.856472  0.697090 -1.098953          1.104037   \n",
       "538   1.902584           -0.856472 -0.846733  0.488555         -1.038638   \n",
       "\n",
       "      Coarse Aggregate  Fine Aggregate       Age  \n",
       "288           1.063368        0.052628  0.860186  \n",
       "1024         -1.467693        0.663784 -0.279597  \n",
       "80           -1.553862        1.415879 -0.675355  \n",
       "320           0.191387        1.439577 -0.501222  \n",
       "538          -0.472245       -0.765572 -0.612034  "
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predictors_norm = (predictors-predictors.mean())/predictors.std()\n",
    "predictors_norm.sample(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's save the number of predictors to *n_cols* since we will need this number when building our network.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_cols = predictors_norm.shape[1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Lets import important `Kera` packages**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "from keras.layers import Input"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Building a Model**\n",
    "\n",
    "Lets define a function that can be used for building model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def regression_model():\n",
    "    # Build model\n",
    "    model = Sequential()\n",
    "    model.add(Input(shape = (n_cols, )))\n",
    "    model.add(Dense(50, activation='relu'))\n",
    "    model.add(Dense(50, activation='relu'))\n",
    "    model.add(Dense(1))\n",
    "\n",
    "    # Compile the model\n",
    "    model.compile(optimizer='adam', \n",
    "                  loss='mean_squared_error')\n",
    "    return model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Train and Test the Model**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-05-03 16:37:05.832994: I metal_plugin/src/device/metal_device.cc:1154] Metal device set to: Apple M2\n",
      "2025-05-03 16:37:05.833020: I metal_plugin/src/device/metal_device.cc:296] systemMemory: 16.00 GB\n",
      "2025-05-03 16:37:05.833028: I metal_plugin/src/device/metal_device.cc:313] maxCacheSize: 5.33 GB\n",
      "2025-05-03 16:37:05.833056: I tensorflow/core/common_runtime/pluggable_device/pluggable_device_factory.cc:306] Could not identify NUMA node of platform GPU ID 0, defaulting to 0. Your kernel may not have been built with NUMA support.\n",
      "2025-05-03 16:37:05.833071: I tensorflow/core/common_runtime/pluggable_device/pluggable_device_factory.cc:272] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 0 MB memory) -> physical PluggableDevice (device: 0, name: METAL, pci bus id: <undefined>)\n"
     ]
    }
   ],
   "source": [
    "model = regression_model()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next, we will train and test the model at the same time using the *fit* method. We will leave out 30% of the data for validation and we will train the model for 100 epochs.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "23/23 [==============================] - 0s 5ms/step - loss: 1658.0022 - val_loss: 1174.7974\n",
      "Epoch 2/100\n",
      "23/23 [==============================] - 0s 5ms/step - loss: 1547.9407 - val_loss: 1099.7601\n",
      "Epoch 3/100\n",
      "23/23 [==============================] - 0s 5ms/step - loss: 1440.9368 - val_loss: 1021.1656\n",
      "Epoch 4/100\n",
      "23/23 [==============================] - 0s 5ms/step - loss: 1316.7897 - val_loss: 934.8947\n",
      "Epoch 5/100\n",
      "23/23 [==============================] - 0s 5ms/step - loss: 1176.6882 - val_loss: 841.4799\n",
      "Epoch 6/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 1033.4349 - val_loss: 750.2767\n",
      "Epoch 7/100\n",
      "23/23 [==============================] - 0s 5ms/step - loss: 901.8964 - val_loss: 655.7469\n",
      "Epoch 8/100\n",
      "23/23 [==============================] - 0s 5ms/step - loss: 782.5415 - val_loss: 571.2643\n",
      "Epoch 9/100\n",
      "23/23 [==============================] - 0s 5ms/step - loss: 681.0488 - val_loss: 489.1803\n",
      "Epoch 10/100\n",
      "23/23 [==============================] - 0s 7ms/step - loss: 585.5928 - val_loss: 412.1028\n",
      "Epoch 11/100\n",
      "23/23 [==============================] - 0s 5ms/step - loss: 495.7859 - val_loss: 337.7698\n",
      "Epoch 12/100\n",
      "23/23 [==============================] - 0s 5ms/step - loss: 410.4469 - val_loss: 270.7480\n",
      "Epoch 13/100\n",
      "23/23 [==============================] - 0s 5ms/step - loss: 335.3825 - val_loss: 213.9893\n",
      "Epoch 14/100\n",
      "23/23 [==============================] - 0s 5ms/step - loss: 267.5918 - val_loss: 165.4109\n",
      "Epoch 15/100\n",
      "23/23 [==============================] - 0s 5ms/step - loss: 214.8257 - val_loss: 128.2423\n",
      "Epoch 16/100\n",
      "23/23 [==============================] - 0s 5ms/step - loss: 176.7579 - val_loss: 104.3515\n",
      "Epoch 17/100\n",
      "23/23 [==============================] - 0s 5ms/step - loss: 152.4833 - val_loss: 91.3424\n",
      "Epoch 18/100\n",
      "23/23 [==============================] - 0s 5ms/step - loss: 140.0018 - val_loss: 84.6596\n",
      "Epoch 19/100\n",
      "23/23 [==============================] - 0s 5ms/step - loss: 133.9189 - val_loss: 82.5676\n",
      "Epoch 20/100\n",
      "23/23 [==============================] - 0s 5ms/step - loss: 131.8725 - val_loss: 81.5715\n",
      "Epoch 21/100\n",
      "23/23 [==============================] - 0s 5ms/step - loss: 130.5785 - val_loss: 82.6231\n",
      "Epoch 22/100\n",
      "23/23 [==============================] - 0s 5ms/step - loss: 130.0320 - val_loss: 83.4623\n",
      "Epoch 23/100\n",
      "23/23 [==============================] - 0s 5ms/step - loss: 129.6921 - val_loss: 84.2436\n",
      "Epoch 24/100\n",
      "23/23 [==============================] - 0s 5ms/step - loss: 129.5654 - val_loss: 84.7234\n",
      "Epoch 25/100\n",
      "23/23 [==============================] - 0s 5ms/step - loss: 129.6645 - val_loss: 84.2906\n",
      "Epoch 26/100\n",
      "23/23 [==============================] - 0s 5ms/step - loss: 129.6369 - val_loss: 85.1402\n",
      "Epoch 27/100\n",
      "23/23 [==============================] - 0s 5ms/step - loss: 129.7177 - val_loss: 85.2986\n",
      "Epoch 28/100\n",
      "23/23 [==============================] - 0s 5ms/step - loss: 130.2201 - val_loss: 85.3159\n",
      "Epoch 29/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 130.6247 - val_loss: 85.7470\n",
      "Epoch 30/100\n",
      "23/23 [==============================] - 0s 6ms/step - loss: 130.9471 - val_loss: 86.5651\n",
      "Epoch 31/100\n",
      "23/23 [==============================] - 0s 5ms/step - loss: 130.6845 - val_loss: 87.7376\n",
      "Epoch 32/100\n",
      "23/23 [==============================] - 0s 5ms/step - loss: 131.0263 - val_loss: 86.0617\n",
      "Epoch 33/100\n",
      "23/23 [==============================] - 0s 5ms/step - loss: 131.4873 - val_loss: 86.9078\n",
      "Epoch 34/100\n",
      "23/23 [==============================] - 0s 5ms/step - loss: 131.4066 - val_loss: 87.0328\n",
      "Epoch 35/100\n",
      "23/23 [==============================] - 0s 5ms/step - loss: 131.7674 - val_loss: 87.0306\n",
      "Epoch 36/100\n",
      "23/23 [==============================] - 0s 5ms/step - loss: 131.6085 - val_loss: 88.1787\n",
      "Epoch 37/100\n",
      "23/23 [==============================] - 0s 5ms/step - loss: 130.2610 - val_loss: 88.3202\n",
      "Epoch 38/100\n",
      "23/23 [==============================] - 0s 5ms/step - loss: 130.0814 - val_loss: 87.2952\n",
      "Epoch 39/100\n",
      "23/23 [==============================] - 0s 5ms/step - loss: 129.8127 - val_loss: 86.7167\n",
      "Epoch 40/100\n",
      "23/23 [==============================] - 0s 5ms/step - loss: 129.8694 - val_loss: 86.1601\n",
      "Epoch 41/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 129.3424 - val_loss: 86.6894\n",
      "Epoch 42/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 129.3788 - val_loss: 84.8474\n",
      "Epoch 43/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 129.2109 - val_loss: 84.7123\n",
      "Epoch 44/100\n",
      "23/23 [==============================] - 0s 5ms/step - loss: 128.9334 - val_loss: 85.0051\n",
      "Epoch 45/100\n",
      "23/23 [==============================] - 0s 5ms/step - loss: 128.9346 - val_loss: 84.0040\n",
      "Epoch 46/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 128.7794 - val_loss: 84.1593\n",
      "Epoch 47/100\n",
      "23/23 [==============================] - 0s 5ms/step - loss: 128.6885 - val_loss: 83.6272\n",
      "Epoch 48/100\n",
      "23/23 [==============================] - 0s 5ms/step - loss: 128.8830 - val_loss: 82.8309\n",
      "Epoch 49/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 128.3105 - val_loss: 83.7550\n",
      "Epoch 50/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 128.3735 - val_loss: 83.7405\n",
      "Epoch 51/100\n",
      "23/23 [==============================] - 0s 5ms/step - loss: 128.4141 - val_loss: 83.5276\n",
      "Epoch 52/100\n",
      "23/23 [==============================] - 0s 6ms/step - loss: 128.4766 - val_loss: 81.7291\n",
      "Epoch 53/100\n",
      "23/23 [==============================] - 0s 5ms/step - loss: 127.7959 - val_loss: 82.6108\n",
      "Epoch 54/100\n",
      "23/23 [==============================] - 0s 5ms/step - loss: 127.9469 - val_loss: 83.0350\n",
      "Epoch 55/100\n",
      "23/23 [==============================] - 0s 5ms/step - loss: 127.9437 - val_loss: 81.7853\n",
      "Epoch 56/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 127.8310 - val_loss: 80.4192\n",
      "Epoch 57/100\n",
      "23/23 [==============================] - 0s 5ms/step - loss: 127.9128 - val_loss: 81.4263\n",
      "Epoch 58/100\n",
      "23/23 [==============================] - 0s 5ms/step - loss: 127.8167 - val_loss: 81.6917\n",
      "Epoch 59/100\n",
      "23/23 [==============================] - 0s 5ms/step - loss: 127.8117 - val_loss: 81.2532\n",
      "Epoch 60/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 127.7634 - val_loss: 81.5364\n",
      "Epoch 61/100\n",
      "23/23 [==============================] - 0s 5ms/step - loss: 127.7753 - val_loss: 81.7897\n",
      "Epoch 62/100\n",
      "23/23 [==============================] - 0s 5ms/step - loss: 127.7653 - val_loss: 81.6429\n",
      "Epoch 63/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 127.6400 - val_loss: 82.6315\n",
      "Epoch 64/100\n",
      "23/23 [==============================] - 0s 5ms/step - loss: 127.6344 - val_loss: 80.5515\n",
      "Epoch 65/100\n",
      "23/23 [==============================] - 0s 5ms/step - loss: 127.8240 - val_loss: 80.8588\n",
      "Epoch 66/100\n",
      "23/23 [==============================] - 0s 5ms/step - loss: 127.8330 - val_loss: 81.2521\n",
      "Epoch 67/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 127.7940 - val_loss: 80.5556\n",
      "Epoch 68/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 128.0042 - val_loss: 81.7911\n",
      "Epoch 69/100\n",
      "23/23 [==============================] - 0s 5ms/step - loss: 127.6350 - val_loss: 80.3350\n",
      "Epoch 70/100\n",
      "23/23 [==============================] - 0s 5ms/step - loss: 127.7121 - val_loss: 80.8038\n",
      "Epoch 71/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 127.6398 - val_loss: 81.7787\n",
      "Epoch 72/100\n",
      "23/23 [==============================] - 0s 6ms/step - loss: 127.7862 - val_loss: 81.3885\n",
      "Epoch 73/100\n",
      "23/23 [==============================] - 0s 5ms/step - loss: 127.6864 - val_loss: 81.6014\n",
      "Epoch 74/100\n",
      "23/23 [==============================] - 0s 5ms/step - loss: 127.7842 - val_loss: 81.5420\n",
      "Epoch 75/100\n",
      "23/23 [==============================] - 0s 5ms/step - loss: 127.7571 - val_loss: 80.3124\n",
      "Epoch 76/100\n",
      "23/23 [==============================] - 0s 5ms/step - loss: 127.9503 - val_loss: 82.3286\n",
      "Epoch 77/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 127.7047 - val_loss: 81.7777\n",
      "Epoch 78/100\n",
      "23/23 [==============================] - 0s 5ms/step - loss: 127.5962 - val_loss: 80.5377\n",
      "Epoch 79/100\n",
      "23/23 [==============================] - 0s 5ms/step - loss: 128.0165 - val_loss: 80.7751\n",
      "Epoch 80/100\n",
      "23/23 [==============================] - 0s 5ms/step - loss: 127.9257 - val_loss: 81.6142\n",
      "Epoch 81/100\n",
      "23/23 [==============================] - 0s 5ms/step - loss: 127.6929 - val_loss: 80.0121\n",
      "Epoch 82/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 127.8388 - val_loss: 81.2949\n",
      "Epoch 83/100\n",
      "23/23 [==============================] - 0s 5ms/step - loss: 127.6654 - val_loss: 81.7934\n",
      "Epoch 84/100\n",
      "23/23 [==============================] - 0s 5ms/step - loss: 127.8380 - val_loss: 80.3468\n",
      "Epoch 85/100\n",
      "23/23 [==============================] - 0s 5ms/step - loss: 127.7096 - val_loss: 80.8201\n",
      "Epoch 86/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 127.6296 - val_loss: 80.8558\n",
      "Epoch 87/100\n",
      "23/23 [==============================] - 0s 5ms/step - loss: 127.6139 - val_loss: 79.8368\n",
      "Epoch 88/100\n",
      "23/23 [==============================] - 0s 5ms/step - loss: 127.6251 - val_loss: 79.6943\n",
      "Epoch 89/100\n",
      "23/23 [==============================] - 0s 5ms/step - loss: 127.7135 - val_loss: 81.0204\n",
      "Epoch 90/100\n",
      "23/23 [==============================] - 0s 5ms/step - loss: 127.5702 - val_loss: 80.3318\n",
      "Epoch 91/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 127.6638 - val_loss: 81.4036\n",
      "Epoch 92/100\n",
      "23/23 [==============================] - 0s 6ms/step - loss: 127.3173 - val_loss: 79.6050\n",
      "Epoch 93/100\n",
      "23/23 [==============================] - 0s 5ms/step - loss: 128.2148 - val_loss: 80.7127\n",
      "Epoch 94/100\n",
      "23/23 [==============================] - 0s 5ms/step - loss: 127.9871 - val_loss: 80.6049\n",
      "Epoch 95/100\n",
      "23/23 [==============================] - 0s 5ms/step - loss: 127.8659 - val_loss: 80.3550\n",
      "Epoch 96/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 127.8762 - val_loss: 80.8378\n",
      "Epoch 97/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 127.4407 - val_loss: 80.8940\n",
      "Epoch 98/100\n",
      "23/23 [==============================] - 0s 5ms/step - loss: 127.8501 - val_loss: 80.2328\n",
      "Epoch 99/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 127.4357 - val_loss: 81.7767\n",
      "Epoch 100/100\n",
      "23/23 [==============================] - 0s 5ms/step - loss: 127.3168 - val_loss: 80.7390\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.src.callbacks.History at 0x309556020>"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(x=predictors_norm, y=target, validation_split=0.3, epochs=100, verbose=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Lets try with 5 number of hidden layers with 50 node each**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "23/23 - 0s - loss: 1665.0046 - val_loss: 1198.5740 - 435ms/epoch - 19ms/step\n",
      "Epoch 2/100\n",
      "23/23 - 0s - loss: 1528.0211 - val_loss: 1193.9980 - 113ms/epoch - 5ms/step\n",
      "Epoch 3/100\n",
      "23/23 - 0s - loss: 1445.1848 - val_loss: 1233.3304 - 150ms/epoch - 7ms/step\n",
      "Epoch 4/100\n",
      "23/23 - 0s - loss: 1348.8033 - val_loss: 1062.0958 - 112ms/epoch - 5ms/step\n",
      "Epoch 5/100\n",
      "23/23 - 0s - loss: 1245.7452 - val_loss: 1355.5321 - 116ms/epoch - 5ms/step\n",
      "Epoch 6/100\n",
      "23/23 - 0s - loss: 4292.9307 - val_loss: 2630.7761 - 121ms/epoch - 5ms/step\n",
      "Epoch 7/100\n",
      "23/23 - 0s - loss: 3778.0906 - val_loss: 643.3236 - 113ms/epoch - 5ms/step\n",
      "Epoch 8/100\n",
      "23/23 - 0s - loss: 4011.8027 - val_loss: 584.6342 - 112ms/epoch - 5ms/step\n",
      "Epoch 9/100\n",
      "23/23 - 0s - loss: 2556.9578 - val_loss: 7002.3237 - 112ms/epoch - 5ms/step\n",
      "Epoch 10/100\n",
      "23/23 - 0s - loss: 26367.2480 - val_loss: 7829.0913 - 111ms/epoch - 5ms/step\n",
      "Epoch 11/100\n",
      "23/23 - 0s - loss: 7623.5298 - val_loss: 726.2114 - 111ms/epoch - 5ms/step\n",
      "Epoch 12/100\n",
      "23/23 - 0s - loss: 2632.7510 - val_loss: 857.0057 - 110ms/epoch - 5ms/step\n",
      "Epoch 13/100\n",
      "23/23 - 0s - loss: 1343.3724 - val_loss: 1297.1311 - 110ms/epoch - 5ms/step\n",
      "Epoch 14/100\n",
      "23/23 - 0s - loss: 3833.0239 - val_loss: 437.9791 - 112ms/epoch - 5ms/step\n",
      "Epoch 15/100\n",
      "23/23 - 0s - loss: 62095.4180 - val_loss: 10992.3721 - 112ms/epoch - 5ms/step\n",
      "Epoch 16/100\n",
      "23/23 - 0s - loss: 23172.0059 - val_loss: 3199.2373 - 112ms/epoch - 5ms/step\n",
      "Epoch 17/100\n",
      "23/23 - 0s - loss: 2623.3721 - val_loss: 801.5285 - 108ms/epoch - 5ms/step\n",
      "Epoch 18/100\n",
      "23/23 - 0s - loss: 47730.2617 - val_loss: 1602.5065 - 109ms/epoch - 5ms/step\n",
      "Epoch 19/100\n",
      "23/23 - 0s - loss: 106263.6016 - val_loss: 27698.9062 - 108ms/epoch - 5ms/step\n",
      "Epoch 20/100\n",
      "23/23 - 0s - loss: 40881.3047 - val_loss: 10060.5977 - 108ms/epoch - 5ms/step\n",
      "Epoch 21/100\n",
      "23/23 - 0s - loss: 18550.2324 - val_loss: 375.3415 - 107ms/epoch - 5ms/step\n",
      "Epoch 22/100\n",
      "23/23 - 0s - loss: 5769.8989 - val_loss: 3708.5288 - 108ms/epoch - 5ms/step\n",
      "Epoch 23/100\n",
      "23/23 - 0s - loss: 18549.0176 - val_loss: 8448.7803 - 110ms/epoch - 5ms/step\n",
      "Epoch 24/100\n",
      "23/23 - 0s - loss: 18786.1562 - val_loss: 2679.4019 - 109ms/epoch - 5ms/step\n",
      "Epoch 25/100\n",
      "23/23 - 0s - loss: 20604.2461 - val_loss: 6023.6050 - 110ms/epoch - 5ms/step\n",
      "Epoch 26/100\n",
      "23/23 - 0s - loss: 13785.3896 - val_loss: 3216.9189 - 112ms/epoch - 5ms/step\n",
      "Epoch 27/100\n",
      "23/23 - 0s - loss: 33211.7344 - val_loss: 4070.7957 - 110ms/epoch - 5ms/step\n",
      "Epoch 28/100\n",
      "23/23 - 0s - loss: 13874.6406 - val_loss: 7925.4224 - 110ms/epoch - 5ms/step\n",
      "Epoch 29/100\n",
      "23/23 - 0s - loss: 29841.2891 - val_loss: 7429.7129 - 109ms/epoch - 5ms/step\n",
      "Epoch 30/100\n",
      "23/23 - 0s - loss: 19149.7324 - val_loss: 2392.7412 - 110ms/epoch - 5ms/step\n",
      "Epoch 31/100\n",
      "23/23 - 0s - loss: 5141.0146 - val_loss: 8983.5859 - 110ms/epoch - 5ms/step\n",
      "Epoch 32/100\n",
      "23/23 - 0s - loss: 179480.3281 - val_loss: 55340.0898 - 109ms/epoch - 5ms/step\n",
      "Epoch 33/100\n",
      "23/23 - 0s - loss: 44092.9062 - val_loss: 1723.9902 - 111ms/epoch - 5ms/step\n",
      "Epoch 34/100\n",
      "23/23 - 0s - loss: 20890.1660 - val_loss: 92882.7344 - 112ms/epoch - 5ms/step\n",
      "Epoch 35/100\n",
      "23/23 - 0s - loss: 1348461.0000 - val_loss: 1089132.8750 - 111ms/epoch - 5ms/step\n",
      "Epoch 36/100\n",
      "23/23 - 0s - loss: 2530780.2500 - val_loss: 5928.1191 - 110ms/epoch - 5ms/step\n",
      "Epoch 37/100\n",
      "23/23 - 0s - loss: 442904.8438 - val_loss: 1379.3430 - 111ms/epoch - 5ms/step\n",
      "Epoch 38/100\n",
      "23/23 - 0s - loss: 85581.1406 - val_loss: 1788.8452 - 113ms/epoch - 5ms/step\n",
      "Epoch 39/100\n",
      "23/23 - 0s - loss: 8098.9507 - val_loss: 1069.7863 - 113ms/epoch - 5ms/step\n",
      "Epoch 40/100\n",
      "23/23 - 0s - loss: 1357.7887 - val_loss: 349.7655 - 111ms/epoch - 5ms/step\n",
      "Epoch 41/100\n",
      "23/23 - 0s - loss: 594.2100 - val_loss: 542.7046 - 109ms/epoch - 5ms/step\n",
      "Epoch 42/100\n",
      "23/23 - 0s - loss: 575.6720 - val_loss: 374.6906 - 109ms/epoch - 5ms/step\n",
      "Epoch 43/100\n",
      "23/23 - 0s - loss: 632.8106 - val_loss: 350.8065 - 111ms/epoch - 5ms/step\n",
      "Epoch 44/100\n",
      "23/23 - 0s - loss: 654.4213 - val_loss: 389.1776 - 113ms/epoch - 5ms/step\n",
      "Epoch 45/100\n",
      "23/23 - 0s - loss: 561.7101 - val_loss: 460.0608 - 111ms/epoch - 5ms/step\n",
      "Epoch 46/100\n",
      "23/23 - 0s - loss: 521.0699 - val_loss: 366.0555 - 121ms/epoch - 5ms/step\n",
      "Epoch 47/100\n",
      "23/23 - 0s - loss: 544.9747 - val_loss: 350.5713 - 111ms/epoch - 5ms/step\n",
      "Epoch 48/100\n",
      "23/23 - 0s - loss: 527.4222 - val_loss: 390.5459 - 147ms/epoch - 6ms/step\n",
      "Epoch 49/100\n",
      "23/23 - 0s - loss: 534.7078 - val_loss: 329.0426 - 110ms/epoch - 5ms/step\n",
      "Epoch 50/100\n",
      "23/23 - 0s - loss: 624.1185 - val_loss: 327.2486 - 110ms/epoch - 5ms/step\n",
      "Epoch 51/100\n",
      "23/23 - 0s - loss: 587.3461 - val_loss: 341.9726 - 110ms/epoch - 5ms/step\n",
      "Epoch 52/100\n",
      "23/23 - 0s - loss: 637.5131 - val_loss: 466.5273 - 109ms/epoch - 5ms/step\n",
      "Epoch 53/100\n",
      "23/23 - 0s - loss: 1127.8745 - val_loss: 459.5178 - 112ms/epoch - 5ms/step\n",
      "Epoch 54/100\n",
      "23/23 - 0s - loss: 1058.0205 - val_loss: 580.6790 - 109ms/epoch - 5ms/step\n",
      "Epoch 55/100\n",
      "23/23 - 0s - loss: 661.9788 - val_loss: 580.3738 - 110ms/epoch - 5ms/step\n",
      "Epoch 56/100\n",
      "23/23 - 0s - loss: 1188.3755 - val_loss: 532.4991 - 110ms/epoch - 5ms/step\n",
      "Epoch 57/100\n",
      "23/23 - 0s - loss: 1342.7974 - val_loss: 620.6013 - 111ms/epoch - 5ms/step\n",
      "Epoch 58/100\n",
      "23/23 - 0s - loss: 2421.1821 - val_loss: 382.8086 - 123ms/epoch - 5ms/step\n",
      "Epoch 59/100\n",
      "23/23 - 0s - loss: 512.1503 - val_loss: 339.3390 - 116ms/epoch - 5ms/step\n",
      "Epoch 60/100\n",
      "23/23 - 0s - loss: 540.2544 - val_loss: 319.8357 - 109ms/epoch - 5ms/step\n",
      "Epoch 61/100\n",
      "23/23 - 0s - loss: 848.5565 - val_loss: 352.0334 - 112ms/epoch - 5ms/step\n",
      "Epoch 62/100\n",
      "23/23 - 0s - loss: 545.7922 - val_loss: 319.2621 - 125ms/epoch - 5ms/step\n",
      "Epoch 63/100\n",
      "23/23 - 0s - loss: 683.0845 - val_loss: 293.1237 - 110ms/epoch - 5ms/step\n",
      "Epoch 64/100\n",
      "23/23 - 0s - loss: 759.9327 - val_loss: 292.6059 - 108ms/epoch - 5ms/step\n",
      "Epoch 65/100\n",
      "23/23 - 0s - loss: 26156.3848 - val_loss: 32106.1133 - 108ms/epoch - 5ms/step\n",
      "Epoch 66/100\n",
      "23/23 - 0s - loss: 158178.9688 - val_loss: 9697.4785 - 107ms/epoch - 5ms/step\n",
      "Epoch 67/100\n",
      "23/23 - 0s - loss: 755023.5625 - val_loss: 60449.9609 - 109ms/epoch - 5ms/step\n",
      "Epoch 68/100\n",
      "23/23 - 0s - loss: 91787.5859 - val_loss: 7303.1279 - 108ms/epoch - 5ms/step\n",
      "Epoch 69/100\n",
      "23/23 - 0s - loss: 24436.1035 - val_loss: 28009.5020 - 109ms/epoch - 5ms/step\n",
      "Epoch 70/100\n",
      "23/23 - 0s - loss: 44607.4648 - val_loss: 27884.3535 - 109ms/epoch - 5ms/step\n",
      "Epoch 71/100\n",
      "23/23 - 0s - loss: 982997.8125 - val_loss: 18146.5898 - 114ms/epoch - 5ms/step\n",
      "Epoch 72/100\n",
      "23/23 - 0s - loss: 195597.5312 - val_loss: 75726.1328 - 107ms/epoch - 5ms/step\n",
      "Epoch 73/100\n",
      "23/23 - 0s - loss: 127439.9219 - val_loss: 16249.0029 - 107ms/epoch - 5ms/step\n",
      "Epoch 74/100\n",
      "23/23 - 0s - loss: 114033.1641 - val_loss: 5235.1216 - 108ms/epoch - 5ms/step\n",
      "Epoch 75/100\n",
      "23/23 - 0s - loss: 3042.0378 - val_loss: 595.0498 - 108ms/epoch - 5ms/step\n",
      "Epoch 76/100\n",
      "23/23 - 0s - loss: 864.6822 - val_loss: 376.1616 - 109ms/epoch - 5ms/step\n",
      "Epoch 77/100\n",
      "23/23 - 0s - loss: 5729.1572 - val_loss: 7348.2534 - 107ms/epoch - 5ms/step\n",
      "Epoch 78/100\n",
      "23/23 - 0s - loss: 46078.4336 - val_loss: 23131.0215 - 108ms/epoch - 5ms/step\n",
      "Epoch 79/100\n",
      "23/23 - 0s - loss: 1831361.8750 - val_loss: 237217.3906 - 108ms/epoch - 5ms/step\n",
      "Epoch 80/100\n",
      "23/23 - 0s - loss: 242375.4531 - val_loss: 34018.0859 - 107ms/epoch - 5ms/step\n",
      "Epoch 81/100\n",
      "23/23 - 0s - loss: 1249719.8750 - val_loss: 15323.8076 - 107ms/epoch - 5ms/step\n",
      "Epoch 82/100\n",
      "23/23 - 0s - loss: 1226639.3750 - val_loss: 620848.5000 - 109ms/epoch - 5ms/step\n",
      "Epoch 83/100\n",
      "23/23 - 0s - loss: 1810983.0000 - val_loss: 426099.2500 - 108ms/epoch - 5ms/step\n",
      "Epoch 84/100\n",
      "23/23 - 0s - loss: 369772.3438 - val_loss: 1465.4821 - 108ms/epoch - 5ms/step\n",
      "Epoch 85/100\n",
      "23/23 - 0s - loss: 9267.8428 - val_loss: 9028.9385 - 107ms/epoch - 5ms/step\n",
      "Epoch 86/100\n",
      "23/23 - 0s - loss: 9791.9697 - val_loss: 2084.9260 - 108ms/epoch - 5ms/step\n",
      "Epoch 87/100\n",
      "23/23 - 0s - loss: 4452.6606 - val_loss: 574.4208 - 146ms/epoch - 6ms/step\n",
      "Epoch 88/100\n",
      "23/23 - 0s - loss: 798.2952 - val_loss: 288.8317 - 109ms/epoch - 5ms/step\n",
      "Epoch 89/100\n",
      "23/23 - 0s - loss: 780.0392 - val_loss: 581.6478 - 108ms/epoch - 5ms/step\n",
      "Epoch 90/100\n",
      "23/23 - 0s - loss: 1972.2594 - val_loss: 374.1740 - 109ms/epoch - 5ms/step\n",
      "Epoch 91/100\n",
      "23/23 - 0s - loss: 482.4379 - val_loss: 347.9980 - 108ms/epoch - 5ms/step\n",
      "Epoch 92/100\n",
      "23/23 - 0s - loss: 836.6498 - val_loss: 367.1373 - 109ms/epoch - 5ms/step\n",
      "Epoch 93/100\n",
      "23/23 - 0s - loss: 567.0456 - val_loss: 312.8730 - 108ms/epoch - 5ms/step\n",
      "Epoch 94/100\n",
      "23/23 - 0s - loss: 498.6892 - val_loss: 275.3469 - 108ms/epoch - 5ms/step\n",
      "Epoch 95/100\n",
      "23/23 - 0s - loss: 449.6175 - val_loss: 473.7684 - 108ms/epoch - 5ms/step\n",
      "Epoch 96/100\n",
      "23/23 - 0s - loss: 1692.3899 - val_loss: 1136.2643 - 107ms/epoch - 5ms/step\n",
      "Epoch 97/100\n",
      "23/23 - 0s - loss: 4114.1787 - val_loss: 1131.1818 - 108ms/epoch - 5ms/step\n",
      "Epoch 98/100\n",
      "23/23 - 0s - loss: 5185.7969 - val_loss: 392.8224 - 107ms/epoch - 5ms/step\n",
      "Epoch 99/100\n",
      "23/23 - 0s - loss: 1101.7543 - val_loss: 299.9991 - 109ms/epoch - 5ms/step\n",
      "Epoch 100/100\n",
      "23/23 - 0s - loss: 1036.2708 - val_loss: 265.2556 - 108ms/epoch - 5ms/step\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.src.callbacks.History at 0x17c2f3d90>"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def model_building():\n",
    "    model = Sequential()\n",
    "    model.add(Input(shape=(n_cols, )))\n",
    "    model.add(Dense(50, activation='relu'))\n",
    "    model.add(Dense(50, activation='relu'))\n",
    "    model.add(Dense(50, activation='relu'))\n",
    "    model.add(Dense(50, activation='relu'))\n",
    "    model.add(Dense(50, activation='relu'))\n",
    "    model.add(Dense(1))\n",
    "\n",
    "    # Compile model\n",
    "    model.compile(optimizer='adam', loss='mean_squared_error')\n",
    "    return model\n",
    "model_ = model_building()\n",
    "model_.fit(predictors_norm, target, validation_split=0.3, verbose=2, epochs=100)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Based on the results, we notice that:\n",
    "\n",
    "- Adding more hidden layers to the model increases its capacity to learn and represent complex relationships within the data. This allows the model to better identify, as a result, the model becomes more effective at fitting the training data and potentially improving its predictions.\n",
    "- By reducing the proportion of data set aside for validation and using a larger portion for training, the model has access to more examples to learn from. This additional training data helps the model improve its understanding of the underlying trends, which can lead to better overall performance.  \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Make Prediction**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "33/33 [==============================] - 0s 1ms/step\n",
      "Actual: 79.990, Predicted: 53.276\n",
      "Actual: 61.890, Predicted: 53.089\n",
      "Actual: 40.270, Predicted: 58.765\n",
      "Actual: 41.050, Predicted: 70.203\n",
      "Actual: 44.300, Predicted: 61.736\n",
      "Actual: 47.030, Predicted: 27.971\n",
      "Actual: 43.700, Predicted: 70.851\n",
      "Actual: 36.450, Predicted: 30.274\n",
      "Actual: 45.850, Predicted: 20.505\n",
      "Actual: 39.290, Predicted: 31.569\n",
      "Actual: 38.070, Predicted: 29.227\n",
      "Actual: 28.020, Predicted: 21.762\n",
      "Actual: 43.010, Predicted: 60.060\n",
      "Actual: 42.330, Predicted: 26.935\n",
      "Actual: 47.810, Predicted: 21.023\n",
      "Actual: 52.910, Predicted: 29.524\n",
      "Actual: 39.360, Predicted: 29.272\n",
      "Actual: 56.140, Predicted: 62.118\n",
      "Actual: 40.560, Predicted: 37.739\n",
      "Actual: 42.620, Predicted: 49.871\n",
      "Actual: 41.840, Predicted: 49.223\n",
      "Actual: 28.240, Predicted: 21.807\n",
      "Actual: 8.060, Predicted: 18.797\n",
      "Actual: 44.210, Predicted: 40.108\n",
      "Actual: 52.520, Predicted: 62.636\n",
      "Actual: 53.300, Predicted: 51.197\n",
      "Actual: 41.150, Predicted: 59.412\n",
      "Actual: 52.120, Predicted: 39.843\n",
      "Actual: 37.430, Predicted: 30.922\n",
      "Actual: 38.600, Predicted: 29.040\n",
      "Actual: 55.260, Predicted: 61.600\n",
      "Actual: 52.910, Predicted: 61.082\n",
      "Actual: 41.720, Predicted: 40.063\n",
      "Actual: 42.130, Predicted: 60.707\n",
      "Actual: 53.690, Predicted: 60.046\n",
      "Actual: 38.410, Predicted: 57.470\n",
      "Actual: 30.080, Predicted: 28.332\n",
      "Actual: 37.720, Predicted: 37.092\n",
      "Actual: 42.230, Predicted: 39.034\n",
      "Actual: 36.250, Predicted: 46.634\n",
      "Actual: 50.460, Predicted: 29.006\n",
      "Actual: 43.700, Predicted: 71.498\n",
      "Actual: 39.000, Predicted: 68.909\n",
      "Actual: 53.100, Predicted: 40.361\n",
      "Actual: 41.540, Predicted: 38.387\n",
      "Actual: 35.080, Predicted: 28.393\n",
      "Actual: 15.050, Predicted: 21.650\n",
      "Actual: 40.760, Predicted: 48.576\n",
      "Actual: 26.260, Predicted: 25.804\n",
      "Actual: 32.820, Predicted: 27.746\n",
      "Actual: 39.780, Predicted: 47.928\n",
      "Actual: 46.930, Predicted: 37.771\n",
      "Actual: 33.120, Predicted: 35.797\n",
      "Actual: 49.190, Predicted: 28.488\n",
      "Actual: 14.590, Predicted: 19.278\n",
      "Actual: 14.640, Predicted: 19.233\n",
      "Actual: 41.930, Predicted: 72.146\n",
      "Actual: 9.130, Predicted: 18.752\n",
      "Actual: 50.950, Predicted: 39.325\n",
      "Actual: 33.020, Predicted: 29.627\n",
      "Actual: 54.380, Predicted: 50.161\n",
      "Actual: 51.730, Predicted: 49.643\n",
      "Actual: 9.870, Predicted: 18.261\n",
      "Actual: 50.660, Predicted: 48.608\n",
      "Actual: 48.700, Predicted: 38.807\n",
      "Actual: 55.060, Predicted: 50.679\n",
      "Actual: 44.700, Predicted: 61.781\n",
      "Actual: 30.280, Predicted: 27.098\n",
      "Actual: 40.860, Predicted: 19.470\n",
      "Actual: 71.990, Predicted: 47.900\n",
      "Actual: 34.400, Predicted: 48.619\n",
      "Actual: 28.800, Predicted: 49.737\n",
      "Actual: 33.400, Predicted: 51.525\n",
      "Actual: 36.300, Predicted: 54.835\n",
      "Actual: 29.000, Predicted: 54.527\n",
      "Actual: 37.800, Predicted: 48.029\n",
      "Actual: 40.200, Predicted: 68.099\n",
      "Actual: 33.400, Predicted: 51.525\n",
      "Actual: 28.100, Predicted: 43.892\n",
      "Actual: 41.300, Predicted: 61.045\n",
      "Actual: 33.400, Predicted: 51.525\n",
      "Actual: 25.200, Predicted: 48.747\n",
      "Actual: 41.100, Predicted: 48.979\n",
      "Actual: 35.300, Predicted: 49.771\n",
      "Actual: 28.300, Predicted: 49.508\n",
      "Actual: 28.600, Predicted: 56.682\n",
      "Actual: 35.300, Predicted: 49.771\n",
      "Actual: 24.400, Predicted: 48.542\n",
      "Actual: 35.300, Predicted: 49.771\n",
      "Actual: 39.300, Predicted: 50.362\n",
      "Actual: 40.600, Predicted: 61.753\n",
      "Actual: 35.300, Predicted: 49.771\n",
      "Actual: 24.100, Predicted: 44.078\n",
      "Actual: 46.200, Predicted: 49.101\n",
      "Actual: 42.800, Predicted: 50.219\n",
      "Actual: 49.200, Predicted: 52.006\n",
      "Actual: 46.800, Predicted: 55.316\n",
      "Actual: 45.700, Predicted: 55.009\n",
      "Actual: 55.600, Predicted: 48.511\n",
      "Actual: 54.900, Predicted: 68.581\n",
      "Actual: 49.200, Predicted: 52.006\n",
      "Actual: 34.900, Predicted: 44.374\n",
      "Actual: 46.900, Predicted: 61.527\n",
      "Actual: 49.200, Predicted: 52.006\n",
      "Actual: 33.400, Predicted: 49.229\n",
      "Actual: 54.100, Predicted: 49.460\n",
      "Actual: 55.900, Predicted: 50.253\n",
      "Actual: 49.800, Predicted: 49.989\n",
      "Actual: 47.100, Predicted: 57.164\n",
      "Actual: 55.900, Predicted: 50.253\n",
      "Actual: 38.000, Predicted: 49.024\n",
      "Actual: 55.900, Predicted: 50.253\n",
      "Actual: 56.100, Predicted: 50.844\n",
      "Actual: 59.090, Predicted: 62.235\n",
      "Actual: 22.900, Predicted: 50.253\n",
      "Actual: 35.100, Predicted: 44.560\n",
      "Actual: 61.090, Predicted: 51.629\n",
      "Actual: 59.800, Predicted: 52.748\n",
      "Actual: 60.290, Predicted: 54.535\n",
      "Actual: 61.800, Predicted: 57.845\n",
      "Actual: 56.700, Predicted: 57.537\n",
      "Actual: 68.300, Predicted: 51.039\n",
      "Actual: 66.900, Predicted: 71.109\n",
      "Actual: 60.290, Predicted: 54.535\n",
      "Actual: 50.700, Predicted: 46.902\n",
      "Actual: 56.400, Predicted: 64.055\n",
      "Actual: 60.290, Predicted: 54.535\n",
      "Actual: 55.500, Predicted: 51.757\n",
      "Actual: 68.500, Predicted: 51.989\n",
      "Actual: 71.300, Predicted: 52.781\n",
      "Actual: 74.700, Predicted: 52.518\n",
      "Actual: 52.200, Predicted: 59.693\n",
      "Actual: 71.300, Predicted: 52.781\n",
      "Actual: 67.700, Predicted: 51.552\n",
      "Actual: 71.300, Predicted: 52.781\n",
      "Actual: 66.000, Predicted: 53.373\n",
      "Actual: 74.500, Predicted: 64.764\n",
      "Actual: 71.300, Predicted: 52.781\n",
      "Actual: 49.900, Predicted: 47.088\n",
      "Actual: 63.400, Predicted: 55.001\n",
      "Actual: 64.900, Predicted: 56.119\n",
      "Actual: 64.300, Predicted: 57.906\n",
      "Actual: 64.900, Predicted: 61.216\n",
      "Actual: 60.200, Predicted: 60.909\n",
      "Actual: 72.300, Predicted: 54.411\n",
      "Actual: 69.300, Predicted: 74.480\n",
      "Actual: 64.300, Predicted: 57.906\n",
      "Actual: 55.200, Predicted: 50.274\n",
      "Actual: 58.800, Predicted: 67.427\n",
      "Actual: 64.300, Predicted: 57.906\n",
      "Actual: 66.100, Predicted: 55.129\n",
      "Actual: 73.700, Predicted: 55.360\n",
      "Actual: 77.300, Predicted: 56.153\n",
      "Actual: 80.200, Predicted: 55.889\n",
      "Actual: 54.900, Predicted: 63.064\n",
      "Actual: 77.300, Predicted: 56.153\n",
      "Actual: 72.990, Predicted: 54.923\n",
      "Actual: 77.300, Predicted: 56.153\n",
      "Actual: 71.700, Predicted: 56.744\n",
      "Actual: 79.400, Predicted: 68.135\n",
      "Actual: 77.300, Predicted: 56.153\n",
      "Actual: 59.890, Predicted: 50.460\n",
      "Actual: 64.900, Predicted: 59.215\n",
      "Actual: 66.600, Predicted: 60.333\n",
      "Actual: 65.200, Predicted: 62.120\n",
      "Actual: 66.700, Predicted: 65.430\n",
      "Actual: 62.500, Predicted: 65.123\n",
      "Actual: 74.190, Predicted: 58.625\n",
      "Actual: 70.700, Predicted: 78.695\n",
      "Actual: 65.200, Predicted: 62.120\n",
      "Actual: 57.600, Predicted: 54.488\n",
      "Actual: 59.200, Predicted: 71.641\n",
      "Actual: 65.200, Predicted: 62.120\n",
      "Actual: 68.100, Predicted: 59.343\n",
      "Actual: 75.500, Predicted: 59.575\n",
      "Actual: 79.300, Predicted: 60.367\n",
      "Actual: 56.500, Predicted: 67.278\n",
      "Actual: 79.300, Predicted: 60.367\n",
      "Actual: 76.800, Predicted: 59.138\n",
      "Actual: 79.300, Predicted: 60.367\n",
      "Actual: 73.300, Predicted: 60.958\n",
      "Actual: 82.600, Predicted: 72.349\n",
      "Actual: 79.300, Predicted: 60.367\n",
      "Actual: 67.800, Predicted: 54.674\n",
      "Actual: 11.580, Predicted: 18.134\n",
      "Actual: 24.450, Predicted: 19.458\n",
      "Actual: 24.890, Predicted: 21.144\n",
      "Actual: 29.450, Predicted: 24.515\n",
      "Actual: 40.710, Predicted: 29.813\n",
      "Actual: 10.380, Predicted: 17.159\n",
      "Actual: 22.140, Predicted: 18.483\n",
      "Actual: 22.840, Predicted: 20.169\n",
      "Actual: 27.660, Predicted: 23.540\n",
      "Actual: 34.560, Predicted: 28.838\n",
      "Actual: 12.450, Predicted: 23.018\n",
      "Actual: 24.990, Predicted: 24.343\n",
      "Actual: 25.720, Predicted: 26.029\n",
      "Actual: 33.960, Predicted: 29.400\n",
      "Actual: 37.340, Predicted: 34.698\n",
      "Actual: 15.040, Predicted: 27.463\n",
      "Actual: 21.060, Predicted: 28.787\n",
      "Actual: 26.400, Predicted: 30.473\n",
      "Actual: 35.340, Predicted: 33.844\n",
      "Actual: 40.570, Predicted: 39.142\n",
      "Actual: 12.470, Predicted: 23.702\n",
      "Actual: 20.920, Predicted: 25.026\n",
      "Actual: 24.900, Predicted: 26.712\n",
      "Actual: 34.200, Predicted: 30.083\n",
      "Actual: 39.610, Predicted: 35.381\n",
      "Actual: 10.030, Predicted: 20.838\n",
      "Actual: 20.080, Predicted: 22.163\n",
      "Actual: 24.480, Predicted: 23.849\n",
      "Actual: 31.540, Predicted: 27.220\n",
      "Actual: 35.340, Predicted: 32.518\n",
      "Actual: 9.450, Predicted: 28.407\n",
      "Actual: 22.720, Predicted: 29.731\n",
      "Actual: 28.470, Predicted: 31.417\n",
      "Actual: 38.560, Predicted: 34.788\n",
      "Actual: 40.390, Predicted: 40.086\n",
      "Actual: 10.760, Predicted: 22.815\n",
      "Actual: 25.480, Predicted: 24.139\n",
      "Actual: 21.540, Predicted: 25.825\n",
      "Actual: 28.630, Predicted: 29.196\n",
      "Actual: 33.540, Predicted: 34.494\n",
      "Actual: 7.750, Predicted: 42.625\n",
      "Actual: 17.820, Predicted: 43.950\n",
      "Actual: 24.240, Predicted: 45.636\n",
      "Actual: 32.850, Predicted: 49.007\n",
      "Actual: 39.230, Predicted: 54.305\n",
      "Actual: 18.000, Predicted: 25.116\n",
      "Actual: 30.390, Predicted: 26.440\n",
      "Actual: 45.710, Predicted: 28.126\n",
      "Actual: 50.770, Predicted: 31.497\n",
      "Actual: 53.900, Predicted: 36.795\n",
      "Actual: 13.180, Predicted: 25.036\n",
      "Actual: 17.840, Predicted: 26.361\n",
      "Actual: 40.230, Predicted: 28.046\n",
      "Actual: 47.130, Predicted: 31.418\n",
      "Actual: 49.970, Predicted: 36.715\n",
      "Actual: 13.360, Predicted: 21.561\n",
      "Actual: 22.320, Predicted: 22.885\n",
      "Actual: 24.540, Predicted: 24.571\n",
      "Actual: 31.350, Predicted: 27.942\n",
      "Actual: 40.860, Predicted: 33.240\n",
      "Actual: 19.930, Predicted: 21.977\n",
      "Actual: 25.690, Predicted: 23.302\n",
      "Actual: 30.230, Predicted: 24.988\n",
      "Actual: 39.590, Predicted: 28.359\n",
      "Actual: 44.300, Predicted: 33.657\n",
      "Actual: 13.820, Predicted: 21.518\n",
      "Actual: 24.920, Predicted: 22.842\n",
      "Actual: 29.220, Predicted: 24.528\n",
      "Actual: 38.330, Predicted: 27.899\n",
      "Actual: 42.350, Predicted: 33.197\n",
      "Actual: 13.540, Predicted: 26.775\n",
      "Actual: 26.310, Predicted: 28.100\n",
      "Actual: 31.640, Predicted: 29.785\n",
      "Actual: 42.550, Predicted: 33.157\n",
      "Actual: 42.920, Predicted: 38.455\n",
      "Actual: 13.330, Predicted: 27.482\n",
      "Actual: 25.370, Predicted: 28.806\n",
      "Actual: 37.400, Predicted: 30.492\n",
      "Actual: 44.400, Predicted: 33.863\n",
      "Actual: 47.740, Predicted: 39.161\n",
      "Actual: 19.520, Predicted: 30.141\n",
      "Actual: 31.350, Predicted: 31.465\n",
      "Actual: 38.500, Predicted: 33.151\n",
      "Actual: 45.080, Predicted: 36.522\n",
      "Actual: 47.820, Predicted: 41.820\n",
      "Actual: 15.440, Predicted: 27.501\n",
      "Actual: 26.770, Predicted: 28.826\n",
      "Actual: 33.730, Predicted: 30.511\n",
      "Actual: 42.700, Predicted: 33.883\n",
      "Actual: 45.840, Predicted: 39.180\n",
      "Actual: 17.220, Predicted: 25.056\n",
      "Actual: 29.930, Predicted: 26.381\n",
      "Actual: 29.650, Predicted: 28.066\n",
      "Actual: 36.970, Predicted: 31.438\n",
      "Actual: 43.580, Predicted: 36.736\n",
      "Actual: 13.120, Predicted: 25.299\n",
      "Actual: 24.430, Predicted: 26.623\n",
      "Actual: 32.660, Predicted: 28.309\n",
      "Actual: 36.640, Predicted: 31.680\n",
      "Actual: 44.210, Predicted: 36.978\n",
      "Actual: 13.620, Predicted: 27.561\n",
      "Actual: 21.600, Predicted: 28.886\n",
      "Actual: 27.770, Predicted: 30.572\n",
      "Actual: 35.570, Predicted: 33.943\n",
      "Actual: 45.370, Predicted: 39.241\n",
      "Actual: 7.320, Predicted: 28.221\n",
      "Actual: 21.500, Predicted: 29.545\n",
      "Actual: 31.270, Predicted: 31.231\n",
      "Actual: 43.500, Predicted: 34.602\n",
      "Actual: 48.670, Predicted: 39.900\n",
      "Actual: 7.400, Predicted: 31.075\n",
      "Actual: 23.510, Predicted: 32.400\n",
      "Actual: 31.120, Predicted: 34.085\n",
      "Actual: 39.150, Predicted: 37.457\n",
      "Actual: 48.150, Predicted: 42.755\n",
      "Actual: 22.500, Predicted: 31.754\n",
      "Actual: 34.670, Predicted: 33.078\n",
      "Actual: 34.740, Predicted: 34.764\n",
      "Actual: 45.080, Predicted: 38.135\n",
      "Actual: 48.970, Predicted: 43.433\n",
      "Actual: 23.140, Predicted: 33.576\n",
      "Actual: 41.890, Predicted: 34.900\n",
      "Actual: 48.280, Predicted: 36.586\n",
      "Actual: 51.040, Predicted: 39.957\n",
      "Actual: 55.640, Predicted: 45.255\n",
      "Actual: 22.950, Predicted: 31.148\n",
      "Actual: 35.230, Predicted: 32.473\n",
      "Actual: 39.940, Predicted: 34.158\n",
      "Actual: 48.720, Predicted: 37.530\n",
      "Actual: 52.040, Predicted: 42.827\n",
      "Actual: 21.020, Predicted: 35.283\n",
      "Actual: 33.360, Predicted: 36.607\n",
      "Actual: 33.940, Predicted: 38.293\n",
      "Actual: 44.140, Predicted: 41.664\n",
      "Actual: 45.370, Predicted: 46.962\n",
      "Actual: 15.360, Predicted: 32.137\n",
      "Actual: 28.680, Predicted: 33.462\n",
      "Actual: 30.850, Predicted: 35.147\n",
      "Actual: 42.030, Predicted: 38.519\n",
      "Actual: 51.060, Predicted: 43.816\n",
      "Actual: 21.780, Predicted: 36.534\n",
      "Actual: 42.290, Predicted: 37.859\n",
      "Actual: 50.600, Predicted: 39.544\n",
      "Actual: 55.830, Predicted: 42.916\n",
      "Actual: 60.950, Predicted: 48.214\n",
      "Actual: 23.520, Predicted: 39.103\n",
      "Actual: 42.220, Predicted: 40.427\n",
      "Actual: 52.500, Predicted: 42.113\n",
      "Actual: 60.320, Predicted: 45.484\n",
      "Actual: 66.420, Predicted: 50.782\n",
      "Actual: 23.800, Predicted: 36.423\n",
      "Actual: 38.770, Predicted: 37.747\n",
      "Actual: 51.330, Predicted: 39.433\n",
      "Actual: 56.850, Predicted: 42.804\n",
      "Actual: 58.610, Predicted: 48.102\n",
      "Actual: 21.910, Predicted: 34.236\n",
      "Actual: 36.990, Predicted: 35.561\n",
      "Actual: 47.400, Predicted: 37.246\n",
      "Actual: 51.960, Predicted: 40.618\n",
      "Actual: 56.740, Predicted: 45.916\n",
      "Actual: 17.570, Predicted: 35.883\n",
      "Actual: 33.730, Predicted: 37.208\n",
      "Actual: 40.150, Predicted: 38.893\n",
      "Actual: 46.640, Predicted: 42.265\n",
      "Actual: 50.080, Predicted: 47.562\n",
      "Actual: 17.370, Predicted: 36.560\n",
      "Actual: 33.700, Predicted: 37.884\n",
      "Actual: 45.940, Predicted: 39.570\n",
      "Actual: 51.430, Predicted: 42.941\n",
      "Actual: 59.300, Predicted: 48.239\n",
      "Actual: 30.450, Predicted: 38.004\n",
      "Actual: 47.710, Predicted: 39.329\n",
      "Actual: 63.140, Predicted: 41.015\n",
      "Actual: 66.820, Predicted: 44.386\n",
      "Actual: 66.950, Predicted: 49.684\n",
      "Actual: 27.420, Predicted: 41.332\n",
      "Actual: 35.960, Predicted: 42.657\n",
      "Actual: 55.510, Predicted: 44.342\n",
      "Actual: 61.990, Predicted: 47.714\n",
      "Actual: 63.530, Predicted: 53.011\n",
      "Actual: 18.020, Predicted: 36.696\n",
      "Actual: 38.600, Predicted: 38.021\n",
      "Actual: 52.200, Predicted: 39.706\n",
      "Actual: 53.960, Predicted: 43.078\n",
      "Actual: 56.630, Predicted: 48.376\n",
      "Actual: 15.340, Predicted: 32.420\n",
      "Actual: 26.050, Predicted: 33.745\n",
      "Actual: 30.220, Predicted: 35.430\n",
      "Actual: 37.270, Predicted: 38.802\n",
      "Actual: 46.230, Predicted: 44.099\n",
      "Actual: 16.280, Predicted: 18.787\n",
      "Actual: 25.620, Predicted: 20.111\n",
      "Actual: 31.970, Predicted: 21.797\n",
      "Actual: 36.300, Predicted: 25.168\n",
      "Actual: 43.060, Predicted: 30.466\n",
      "Actual: 67.570, Predicted: 52.530\n",
      "Actual: 57.230, Predicted: 57.467\n",
      "Actual: 81.750, Predicted: 48.089\n",
      "Actual: 64.020, Predicted: 43.980\n",
      "Actual: 78.800, Predicted: 47.209\n",
      "Actual: 41.370, Predicted: 52.479\n",
      "Actual: 60.280, Predicted: 46.628\n",
      "Actual: 56.830, Predicted: 47.148\n",
      "Actual: 51.020, Predicted: 46.633\n",
      "Actual: 55.550, Predicted: 54.791\n",
      "Actual: 44.130, Predicted: 40.097\n",
      "Actual: 39.380, Predicted: 39.416\n",
      "Actual: 55.650, Predicted: 59.055\n",
      "Actual: 47.280, Predicted: 52.457\n",
      "Actual: 44.330, Predicted: 45.569\n",
      "Actual: 52.300, Predicted: 36.847\n",
      "Actual: 49.250, Predicted: 30.075\n",
      "Actual: 41.370, Predicted: 52.520\n",
      "Actual: 29.160, Predicted: 26.774\n",
      "Actual: 39.400, Predicted: 29.742\n",
      "Actual: 39.300, Predicted: 31.242\n",
      "Actual: 67.870, Predicted: 48.703\n",
      "Actual: 58.520, Predicted: 51.814\n",
      "Actual: 53.580, Predicted: 47.524\n",
      "Actual: 59.000, Predicted: 50.561\n",
      "Actual: 76.240, Predicted: 52.633\n",
      "Actual: 69.840, Predicted: 57.160\n",
      "Actual: 14.400, Predicted: 20.441\n",
      "Actual: 19.420, Predicted: 32.644\n",
      "Actual: 20.730, Predicted: 29.767\n",
      "Actual: 14.940, Predicted: 32.499\n",
      "Actual: 21.290, Predicted: 28.350\n",
      "Actual: 23.080, Predicted: 31.322\n",
      "Actual: 15.520, Predicted: 33.658\n",
      "Actual: 15.820, Predicted: 33.909\n",
      "Actual: 12.550, Predicted: 27.213\n",
      "Actual: 8.490, Predicted: 20.332\n",
      "Actual: 15.610, Predicted: 35.389\n",
      "Actual: 12.180, Predicted: 21.860\n",
      "Actual: 11.980, Predicted: 23.642\n",
      "Actual: 16.880, Predicted: 21.766\n",
      "Actual: 33.090, Predicted: 33.969\n",
      "Actual: 34.240, Predicted: 31.092\n",
      "Actual: 31.810, Predicted: 33.823\n",
      "Actual: 29.750, Predicted: 29.674\n",
      "Actual: 33.010, Predicted: 32.646\n",
      "Actual: 32.900, Predicted: 34.983\n",
      "Actual: 29.550, Predicted: 35.233\n",
      "Actual: 19.420, Predicted: 28.538\n",
      "Actual: 24.660, Predicted: 21.656\n",
      "Actual: 29.590, Predicted: 36.713\n",
      "Actual: 24.280, Predicted: 23.185\n",
      "Actual: 20.730, Predicted: 24.967\n",
      "Actual: 26.200, Predicted: 23.451\n",
      "Actual: 46.390, Predicted: 35.654\n",
      "Actual: 39.160, Predicted: 32.777\n",
      "Actual: 41.200, Predicted: 35.509\n",
      "Actual: 33.690, Predicted: 31.360\n",
      "Actual: 38.200, Predicted: 34.332\n",
      "Actual: 41.410, Predicted: 36.669\n",
      "Actual: 37.810, Predicted: 36.919\n",
      "Actual: 24.850, Predicted: 30.223\n",
      "Actual: 27.220, Predicted: 23.342\n",
      "Actual: 44.640, Predicted: 38.399\n",
      "Actual: 37.270, Predicted: 24.871\n",
      "Actual: 33.270, Predicted: 26.653\n",
      "Actual: 36.560, Predicted: 26.823\n",
      "Actual: 53.720, Predicted: 39.026\n",
      "Actual: 48.590, Predicted: 36.149\n",
      "Actual: 51.720, Predicted: 38.880\n",
      "Actual: 35.850, Predicted: 34.731\n",
      "Actual: 53.770, Predicted: 37.703\n",
      "Actual: 53.460, Predicted: 40.040\n",
      "Actual: 48.990, Predicted: 40.290\n",
      "Actual: 31.720, Predicted: 33.595\n",
      "Actual: 39.640, Predicted: 26.713\n",
      "Actual: 51.260, Predicted: 41.770\n",
      "Actual: 43.390, Predicted: 28.242\n",
      "Actual: 39.270, Predicted: 30.024\n",
      "Actual: 37.960, Predicted: 32.120\n",
      "Actual: 55.020, Predicted: 44.323\n",
      "Actual: 49.990, Predicted: 41.447\n",
      "Actual: 53.660, Predicted: 44.178\n",
      "Actual: 37.680, Predicted: 40.029\n",
      "Actual: 56.060, Predicted: 43.001\n",
      "Actual: 56.810, Predicted: 45.338\n",
      "Actual: 50.940, Predicted: 45.588\n",
      "Actual: 33.560, Predicted: 38.892\n",
      "Actual: 41.160, Predicted: 32.011\n",
      "Actual: 52.960, Predicted: 47.068\n",
      "Actual: 44.280, Predicted: 33.540\n",
      "Actual: 40.150, Predicted: 35.322\n",
      "Actual: 57.030, Predicted: 54.662\n",
      "Actual: 44.420, Predicted: 54.662\n",
      "Actual: 51.020, Predicted: 54.662\n",
      "Actual: 53.390, Predicted: 54.136\n",
      "Actual: 35.360, Predicted: 51.652\n",
      "Actual: 25.020, Predicted: 51.652\n",
      "Actual: 23.350, Predicted: 51.652\n",
      "Actual: 52.010, Predicted: 52.133\n",
      "Actual: 38.020, Predicted: 52.133\n",
      "Actual: 39.300, Predicted: 52.133\n",
      "Actual: 61.070, Predicted: 58.033\n",
      "Actual: 56.140, Predicted: 58.033\n",
      "Actual: 55.250, Predicted: 58.033\n",
      "Actual: 54.770, Predicted: 57.508\n",
      "Actual: 50.240, Predicted: 49.207\n",
      "Actual: 46.680, Predicted: 49.045\n",
      "Actual: 46.680, Predicted: 48.115\n",
      "Actual: 22.750, Predicted: 46.196\n",
      "Actual: 25.510, Predicted: 46.035\n",
      "Actual: 34.770, Predicted: 45.105\n",
      "Actual: 36.840, Predicted: 46.678\n",
      "Actual: 45.900, Predicted: 46.516\n",
      "Actual: 41.670, Predicted: 45.587\n",
      "Actual: 56.340, Predicted: 52.578\n",
      "Actual: 47.970, Predicted: 52.416\n",
      "Actual: 61.460, Predicted: 51.486\n",
      "Actual: 44.030, Predicted: 48.876\n",
      "Actual: 55.450, Predicted: 48.553\n",
      "Actual: 55.550, Predicted: 43.720\n",
      "Actual: 57.920, Predicted: 47.210\n",
      "Actual: 25.610, Predicted: 40.710\n",
      "Actual: 33.490, Predicted: 41.191\n",
      "Actual: 59.590, Predicted: 47.091\n",
      "Actual: 29.550, Predicted: 44.199\n",
      "Actual: 37.920, Predicted: 44.681\n",
      "Actual: 61.860, Predicted: 50.581\n",
      "Actual: 62.050, Predicted: 49.623\n",
      "Actual: 32.010, Predicted: 45.868\n",
      "Actual: 72.100, Predicted: 52.834\n",
      "Actual: 39.000, Predicted: 47.094\n",
      "Actual: 65.700, Predicted: 52.994\n",
      "Actual: 32.110, Predicted: 49.824\n",
      "Actual: 40.290, Predicted: 50.306\n",
      "Actual: 74.360, Predicted: 56.205\n",
      "Actual: 21.970, Predicted: 18.710\n",
      "Actual: 9.850, Predicted: 15.700\n",
      "Actual: 15.070, Predicted: 16.181\n",
      "Actual: 23.250, Predicted: 22.081\n",
      "Actual: 43.730, Predicted: 35.915\n",
      "Actual: 13.400, Predicted: 32.905\n",
      "Actual: 24.130, Predicted: 33.387\n",
      "Actual: 44.520, Predicted: 39.287\n",
      "Actual: 62.940, Predicted: 50.166\n",
      "Actual: 59.490, Predicted: 50.166\n",
      "Actual: 25.120, Predicted: 47.156\n",
      "Actual: 23.640, Predicted: 47.156\n",
      "Actual: 35.750, Predicted: 47.638\n",
      "Actual: 38.610, Predicted: 47.638\n",
      "Actual: 68.750, Predicted: 53.538\n",
      "Actual: 66.780, Predicted: 53.538\n",
      "Actual: 23.850, Predicted: 28.634\n",
      "Actual: 32.070, Predicted: 26.394\n",
      "Actual: 11.650, Predicted: 15.919\n",
      "Actual: 19.200, Predicted: 26.899\n",
      "Actual: 48.850, Predicted: 37.374\n",
      "Actual: 39.600, Predicted: 29.909\n",
      "Actual: 43.940, Predicted: 38.803\n",
      "Actual: 34.570, Predicted: 36.274\n",
      "Actual: 54.320, Predicted: 46.268\n",
      "Actual: 24.400, Predicted: 35.793\n",
      "Actual: 15.620, Predicted: 20.700\n",
      "Actual: 21.860, Predicted: 22.509\n",
      "Actual: 10.220, Predicted: 12.515\n",
      "Actual: 14.600, Predicted: 16.400\n",
      "Actual: 18.750, Predicted: 15.044\n",
      "Actual: 31.970, Predicted: 23.710\n",
      "Actual: 23.400, Predicted: 21.182\n",
      "Actual: 25.570, Predicted: 18.929\n",
      "Actual: 41.680, Predicted: 31.176\n",
      "Actual: 27.740, Predicted: 27.380\n",
      "Actual: 8.200, Predicted: 12.034\n",
      "Actual: 9.620, Predicted: 26.865\n",
      "Actual: 25.420, Predicted: 43.520\n",
      "Actual: 15.690, Predicted: 27.947\n",
      "Actual: 27.940, Predicted: 34.150\n",
      "Actual: 32.630, Predicted: 36.540\n",
      "Actual: 17.240, Predicted: 30.400\n",
      "Actual: 19.770, Predicted: 32.861\n",
      "Actual: 39.440, Predicted: 46.048\n",
      "Actual: 25.750, Predicted: 28.005\n",
      "Actual: 33.080, Predicted: 32.640\n",
      "Actual: 24.070, Predicted: 28.797\n",
      "Actual: 21.820, Predicted: 37.567\n",
      "Actual: 21.070, Predicted: 29.394\n",
      "Actual: 14.840, Predicted: 20.928\n",
      "Actual: 32.050, Predicted: 32.928\n",
      "Actual: 11.960, Predicted: 22.763\n",
      "Actual: 25.450, Predicted: 30.111\n",
      "Actual: 22.490, Predicted: 28.996\n",
      "Actual: 25.220, Predicted: 23.456\n",
      "Actual: 39.700, Predicted: 43.665\n",
      "Actual: 13.090, Predicted: 25.477\n",
      "Actual: 38.700, Predicted: 41.532\n",
      "Actual: 7.510, Predicted: 21.839\n",
      "Actual: 17.580, Predicted: 18.238\n",
      "Actual: 21.180, Predicted: 24.871\n",
      "Actual: 18.200, Predicted: 24.368\n",
      "Actual: 17.200, Predicted: 34.011\n",
      "Actual: 22.630, Predicted: 25.292\n",
      "Actual: 21.860, Predicted: 35.329\n",
      "Actual: 12.370, Predicted: 31.622\n",
      "Actual: 25.730, Predicted: 25.865\n",
      "Actual: 37.810, Predicted: 40.096\n",
      "Actual: 21.920, Predicted: 41.137\n",
      "Actual: 33.040, Predicted: 37.857\n",
      "Actual: 14.540, Predicted: 26.468\n",
      "Actual: 26.910, Predicted: 30.476\n",
      "Actual: 8.000, Predicted: 20.561\n",
      "Actual: 31.900, Predicted: 27.399\n",
      "Actual: 10.340, Predicted: 15.709\n",
      "Actual: 19.770, Predicted: 19.545\n",
      "Actual: 37.440, Predicted: 31.326\n",
      "Actual: 11.480, Predicted: 17.016\n",
      "Actual: 24.440, Predicted: 39.004\n",
      "Actual: 17.600, Predicted: 23.089\n",
      "Actual: 10.730, Predicted: 23.336\n",
      "Actual: 31.380, Predicted: 35.389\n",
      "Actual: 13.220, Predicted: 21.268\n",
      "Actual: 20.970, Predicted: 21.750\n",
      "Actual: 27.040, Predicted: 22.593\n",
      "Actual: 32.040, Predicted: 24.279\n",
      "Actual: 35.170, Predicted: 31.744\n",
      "Actual: 36.450, Predicted: 42.580\n",
      "Actual: 38.890, Predicted: 64.855\n",
      "Actual: 6.470, Predicted: 11.131\n",
      "Actual: 12.840, Predicted: 12.456\n",
      "Actual: 18.420, Predicted: 14.142\n",
      "Actual: 21.950, Predicted: 21.607\n",
      "Actual: 24.100, Predicted: 32.748\n",
      "Actual: 25.080, Predicted: 55.023\n",
      "Actual: 21.260, Predicted: 17.345\n",
      "Actual: 25.970, Predicted: 19.030\n",
      "Actual: 11.360, Predicted: 16.020\n",
      "Actual: 31.250, Predicted: 26.496\n",
      "Actual: 32.330, Predicted: 37.332\n",
      "Actual: 33.700, Predicted: 59.005\n",
      "Actual: 9.310, Predicted: 11.974\n",
      "Actual: 26.940, Predicted: 22.450\n",
      "Actual: 27.630, Predicted: 33.286\n",
      "Actual: 29.790, Predicted: 55.561\n",
      "Actual: 34.490, Predicted: 40.411\n",
      "Actual: 36.150, Predicted: 62.686\n",
      "Actual: 12.540, Predicted: 19.100\n",
      "Actual: 27.530, Predicted: 22.110\n",
      "Actual: 32.920, Predicted: 29.575\n",
      "Actual: 9.990, Predicted: 11.918\n",
      "Actual: 7.840, Predicted: 12.691\n",
      "Actual: 12.250, Predicted: 15.220\n",
      "Actual: 11.170, Predicted: 14.763\n",
      "Actual: 17.340, Predicted: 17.292\n",
      "Actual: 17.540, Predicted: 23.450\n",
      "Actual: 30.570, Predicted: 25.978\n",
      "Actual: 14.200, Predicted: 18.954\n",
      "Actual: 24.500, Predicted: 21.482\n",
      "Actual: 15.580, Predicted: 21.073\n",
      "Actual: 26.850, Predicted: 23.601\n",
      "Actual: 26.060, Predicted: 27.641\n",
      "Actual: 38.210, Predicted: 30.169\n",
      "Actual: 43.700, Predicted: 32.288\n",
      "Actual: 30.140, Predicted: 29.759\n",
      "Actual: 12.730, Predicted: 16.882\n",
      "Actual: 20.870, Predicted: 19.410\n",
      "Actual: 20.280, Predicted: 25.264\n",
      "Actual: 34.290, Predicted: 27.792\n",
      "Actual: 19.540, Predicted: 33.182\n",
      "Actual: 47.710, Predicted: 36.018\n",
      "Actual: 43.380, Predicted: 34.373\n",
      "Actual: 29.890, Predicted: 21.514\n",
      "Actual: 6.900, Predicted: 24.482\n",
      "Actual: 33.190, Predicted: 24.360\n",
      "Actual: 4.900, Predicted: 14.711\n",
      "Actual: 4.570, Predicted: 10.086\n",
      "Actual: 25.460, Predicted: 20.561\n",
      "Actual: 24.290, Predicted: 16.895\n",
      "Actual: 33.950, Predicted: 27.492\n",
      "Actual: 11.410, Predicted: 19.712\n",
      "Actual: 20.590, Predicted: 13.157\n",
      "Actual: 25.890, Predicted: 34.510\n",
      "Actual: 29.230, Predicted: 20.622\n",
      "Actual: 31.020, Predicted: 24.195\n",
      "Actual: 10.390, Predicted: 18.986\n",
      "Actual: 33.660, Predicted: 26.908\n",
      "Actual: 27.870, Predicted: 21.149\n",
      "Actual: 19.350, Predicted: 26.024\n",
      "Actual: 11.390, Predicted: 15.724\n",
      "Actual: 12.790, Predicted: 31.813\n",
      "Actual: 39.320, Predicted: 34.824\n",
      "Actual: 4.780, Predicted: 10.731\n",
      "Actual: 16.110, Predicted: 33.036\n",
      "Actual: 43.380, Predicted: 37.039\n",
      "Actual: 20.420, Predicted: 26.096\n",
      "Actual: 6.940, Predicted: 15.242\n",
      "Actual: 15.030, Predicted: 19.878\n",
      "Actual: 13.570, Predicted: 25.614\n",
      "Actual: 32.530, Predicted: 25.187\n",
      "Actual: 15.750, Predicted: 24.964\n",
      "Actual: 7.680, Predicted: 10.568\n",
      "Actual: 38.800, Predicted: 36.046\n",
      "Actual: 33.000, Predicted: 22.406\n",
      "Actual: 17.280, Predicted: 13.096\n",
      "Actual: 24.280, Predicted: 18.252\n",
      "Actual: 24.050, Predicted: 17.721\n",
      "Actual: 36.590, Predicted: 28.614\n",
      "Actual: 50.730, Predicted: 42.289\n",
      "Actual: 13.660, Predicted: 18.620\n",
      "Actual: 14.140, Predicted: 34.029\n",
      "Actual: 47.780, Predicted: 36.090\n",
      "Actual: 2.330, Predicted: 10.147\n",
      "Actual: 16.890, Predicted: 24.380\n",
      "Actual: 23.520, Predicted: 33.518\n",
      "Actual: 6.810, Predicted: 19.396\n",
      "Actual: 39.700, Predicted: 29.871\n",
      "Actual: 17.960, Predicted: 13.741\n",
      "Actual: 32.880, Predicted: 28.625\n",
      "Actual: 22.350, Predicted: 16.730\n",
      "Actual: 10.790, Predicted: 15.193\n",
      "Actual: 7.720, Predicted: 10.629\n",
      "Actual: 41.680, Predicted: 35.710\n",
      "Actual: 9.560, Predicted: 32.700\n",
      "Actual: 6.880, Predicted: 18.139\n",
      "Actual: 50.530, Predicted: 43.511\n",
      "Actual: 17.170, Predicted: 20.194\n",
      "Actual: 30.440, Predicted: 22.722\n",
      "Actual: 9.730, Predicted: 25.543\n",
      "Actual: 3.320, Predicted: 13.885\n",
      "Actual: 26.320, Predicted: 21.206\n",
      "Actual: 43.250, Predicted: 30.188\n",
      "Actual: 6.280, Predicted: 13.720\n",
      "Actual: 32.100, Predicted: 25.717\n",
      "Actual: 36.960, Predicted: 28.553\n",
      "Actual: 54.600, Predicted: 44.504\n",
      "Actual: 21.480, Predicted: 32.295\n",
      "Actual: 9.690, Predicted: 23.898\n",
      "Actual: 8.370, Predicted: 11.213\n",
      "Actual: 39.660, Predicted: 28.979\n",
      "Actual: 10.090, Predicted: 14.201\n",
      "Actual: 4.830, Predicted: 18.504\n",
      "Actual: 10.350, Predicted: 14.367\n",
      "Actual: 43.570, Predicted: 34.958\n",
      "Actual: 51.860, Predicted: 43.176\n",
      "Actual: 11.850, Predicted: 18.459\n",
      "Actual: 17.240, Predicted: 18.940\n",
      "Actual: 27.830, Predicted: 21.469\n",
      "Actual: 35.760, Predicted: 28.934\n",
      "Actual: 38.700, Predicted: 32.546\n",
      "Actual: 14.310, Predicted: 20.132\n",
      "Actual: 17.440, Predicted: 20.614\n",
      "Actual: 31.740, Predicted: 23.142\n",
      "Actual: 37.910, Predicted: 30.607\n",
      "Actual: 39.380, Predicted: 34.219\n",
      "Actual: 15.870, Predicted: 21.467\n",
      "Actual: 9.010, Predicted: 21.948\n",
      "Actual: 33.610, Predicted: 24.477\n",
      "Actual: 40.660, Predicted: 31.942\n",
      "Actual: 40.860, Predicted: 35.554\n",
      "Actual: 12.050, Predicted: 15.618\n",
      "Actual: 17.540, Predicted: 18.147\n",
      "Actual: 18.910, Predicted: 20.878\n",
      "Actual: 25.180, Predicted: 23.407\n",
      "Actual: 30.960, Predicted: 22.773\n",
      "Actual: 43.890, Predicted: 38.503\n",
      "Actual: 54.280, Predicted: 45.969\n",
      "Actual: 36.940, Predicted: 32.566\n",
      "Actual: 14.500, Predicted: 19.443\n",
      "Actual: 22.440, Predicted: 22.277\n",
      "Actual: 12.640, Predicted: 35.626\n",
      "Actual: 26.060, Predicted: 35.867\n",
      "Actual: 33.210, Predicted: 36.348\n",
      "Actual: 36.940, Predicted: 37.191\n",
      "Actual: 44.090, Predicted: 38.877\n",
      "Actual: 52.610, Predicted: 47.489\n",
      "Actual: 59.760, Predicted: 48.331\n",
      "Actual: 67.310, Predicted: 50.017\n",
      "Actual: 69.660, Predicted: 57.482\n",
      "Actual: 71.620, Predicted: 68.319\n",
      "Actual: 74.170, Predicted: 79.155\n",
      "Actual: 18.130, Predicted: 20.851\n",
      "Actual: 22.530, Predicted: 21.694\n",
      "Actual: 27.340, Predicted: 23.379\n",
      "Actual: 29.980, Predicted: 26.751\n",
      "Actual: 31.350, Predicted: 30.844\n",
      "Actual: 32.720, Predicted: 41.681\n",
      "Actual: 6.270, Predicted: 28.367\n",
      "Actual: 14.700, Predicted: 28.608\n",
      "Actual: 23.220, Predicted: 29.089\n",
      "Actual: 27.920, Predicted: 29.932\n",
      "Actual: 31.350, Predicted: 31.618\n",
      "Actual: 39.000, Predicted: 41.890\n",
      "Actual: 41.240, Predicted: 63.563\n",
      "Actual: 14.990, Predicted: 21.681\n",
      "Actual: 13.520, Predicted: 20.578\n",
      "Actual: 24.000, Predicted: 28.689\n",
      "Actual: 37.420, Predicted: 31.218\n",
      "Actual: 11.470, Predicted: 26.351\n",
      "Actual: 22.440, Predicted: 21.972\n",
      "Actual: 21.160, Predicted: 25.083\n",
      "Actual: 31.840, Predicted: 27.611\n",
      "Actual: 14.800, Predicted: 21.371\n",
      "Actual: 25.180, Predicted: 23.900\n",
      "Actual: 17.540, Predicted: 18.464\n",
      "Actual: 14.200, Predicted: 19.248\n",
      "Actual: 21.650, Predicted: 21.776\n",
      "Actual: 29.390, Predicted: 29.241\n",
      "Actual: 13.520, Predicted: 21.807\n",
      "Actual: 16.260, Predicted: 21.060\n",
      "Actual: 31.450, Predicted: 23.588\n",
      "Actual: 37.230, Predicted: 31.053\n",
      "Actual: 18.130, Predicted: 22.163\n",
      "Actual: 32.720, Predicted: 24.691\n",
      "Actual: 39.490, Predicted: 32.157\n",
      "Actual: 41.050, Predicted: 42.993\n",
      "Actual: 42.130, Predicted: 64.666\n",
      "Actual: 18.130, Predicted: 16.765\n",
      "Actual: 26.740, Predicted: 36.752\n",
      "Actual: 61.920, Predicted: 62.349\n",
      "Actual: 47.220, Predicted: 46.342\n",
      "Actual: 51.040, Predicted: 57.178\n",
      "Actual: 55.160, Predicted: 68.015\n",
      "Actual: 41.640, Predicted: 47.007\n",
      "Actual: 13.710, Predicted: 17.211\n",
      "Actual: 19.690, Predicted: 19.740\n",
      "Actual: 31.650, Predicted: 27.723\n",
      "Actual: 19.110, Predicted: 27.853\n",
      "Actual: 39.580, Predicted: 30.863\n",
      "Actual: 48.790, Predicted: 38.329\n",
      "Actual: 24.000, Predicted: 28.994\n",
      "Actual: 37.420, Predicted: 31.523\n",
      "Actual: 11.470, Predicted: 16.906\n",
      "Actual: 19.690, Predicted: 19.740\n",
      "Actual: 14.990, Predicted: 18.775\n",
      "Actual: 27.920, Predicted: 21.304\n",
      "Actual: 34.680, Predicted: 28.769\n",
      "Actual: 37.330, Predicted: 39.606\n",
      "Actual: 38.110, Predicted: 61.278\n",
      "Actual: 33.800, Predicted: 41.038\n",
      "Actual: 42.420, Predicted: 41.519\n",
      "Actual: 48.400, Predicted: 42.362\n",
      "Actual: 55.940, Predicted: 44.048\n",
      "Actual: 58.780, Predicted: 51.513\n",
      "Actual: 67.110, Predicted: 73.186\n",
      "Actual: 20.770, Predicted: 18.802\n",
      "Actual: 25.180, Predicted: 20.487\n",
      "Actual: 29.590, Predicted: 38.789\n",
      "Actual: 21.750, Predicted: 18.451\n",
      "Actual: 39.090, Predicted: 32.871\n",
      "Actual: 24.390, Predicted: 35.493\n",
      "Actual: 50.510, Predicted: 47.546\n",
      "Actual: 74.990, Predicted: 50.075\n",
      "Actual: 37.170, Predicted: 33.195\n",
      "Actual: 33.760, Predicted: 45.252\n",
      "Actual: 16.500, Predicted: 26.035\n",
      "Actual: 19.990, Predicted: 22.810\n",
      "Actual: 36.350, Predicted: 46.638\n",
      "Actual: 33.690, Predicted: 58.328\n",
      "Actual: 15.420, Predicted: 35.072\n",
      "Actual: 33.420, Predicted: 30.171\n",
      "Actual: 39.050, Predicted: 32.978\n",
      "Actual: 27.680, Predicted: 40.113\n",
      "Actual: 26.860, Predicted: 29.289\n",
      "Actual: 45.300, Predicted: 43.380\n",
      "Actual: 30.120, Predicted: 33.242\n",
      "Actual: 15.570, Predicted: 32.678\n",
      "Actual: 44.610, Predicted: 37.878\n",
      "Actual: 53.520, Predicted: 40.705\n",
      "Actual: 57.210, Predicted: 38.263\n",
      "Actual: 65.910, Predicted: 44.548\n",
      "Actual: 52.820, Predicted: 44.186\n",
      "Actual: 33.400, Predicted: 31.429\n",
      "Actual: 18.030, Predicted: 28.714\n",
      "Actual: 37.360, Predicted: 37.135\n",
      "Actual: 32.840, Predicted: 35.524\n",
      "Actual: 42.640, Predicted: 31.690\n",
      "Actual: 40.060, Predicted: 29.553\n",
      "Actual: 41.940, Predicted: 41.841\n",
      "Actual: 61.230, Predicted: 44.543\n",
      "Actual: 40.870, Predicted: 39.556\n",
      "Actual: 33.300, Predicted: 38.796\n",
      "Actual: 52.420, Predicted: 41.108\n",
      "Actual: 15.090, Predicted: 29.679\n",
      "Actual: 38.460, Predicted: 40.138\n",
      "Actual: 37.260, Predicted: 38.832\n",
      "Actual: 35.230, Predicted: 20.835\n",
      "Actual: 42.130, Predicted: 35.742\n",
      "Actual: 31.870, Predicted: 28.816\n",
      "Actual: 41.540, Predicted: 33.611\n",
      "Actual: 39.450, Predicted: 41.911\n",
      "Actual: 37.910, Predicted: 36.355\n",
      "Actual: 44.280, Predicted: 40.963\n",
      "Actual: 31.180, Predicted: 33.220\n",
      "Actual: 23.690, Predicted: 28.061\n",
      "Actual: 32.760, Predicted: 32.542\n",
      "Actual: 32.400, Predicted: 32.315\n",
      "Actual: 28.630, Predicted: 16.954\n",
      "Actual: 36.800, Predicted: 39.087\n",
      "Actual: 18.280, Predicted: 28.472\n",
      "Actual: 33.060, Predicted: 22.147\n",
      "Actual: 31.420, Predicted: 24.906\n",
      "Actual: 31.030, Predicted: 22.980\n",
      "Actual: 44.390, Predicted: 39.755\n",
      "Actual: 12.180, Predicted: 21.283\n",
      "Actual: 25.560, Predicted: 36.021\n",
      "Actual: 36.440, Predicted: 25.690\n",
      "Actual: 32.960, Predicted: 33.723\n",
      "Actual: 23.840, Predicted: 29.089\n",
      "Actual: 26.230, Predicted: 33.064\n",
      "Actual: 17.950, Predicted: 32.643\n",
      "Actual: 40.680, Predicted: 34.892\n",
      "Actual: 19.010, Predicted: 26.548\n",
      "Actual: 33.720, Predicted: 34.176\n",
      "Actual: 8.540, Predicted: 20.278\n",
      "Actual: 13.460, Predicted: 36.534\n",
      "Actual: 32.240, Predicted: 28.361\n",
      "Actual: 23.520, Predicted: 28.777\n",
      "Actual: 29.720, Predicted: 36.070\n",
      "Actual: 49.770, Predicted: 40.893\n",
      "Actual: 52.440, Predicted: 43.117\n",
      "Actual: 40.930, Predicted: 38.569\n",
      "Actual: 44.860, Predicted: 28.389\n",
      "Actual: 13.200, Predicted: 24.161\n",
      "Actual: 37.430, Predicted: 38.785\n",
      "Actual: 29.870, Predicted: 31.800\n",
      "Actual: 56.610, Predicted: 38.803\n",
      "Actual: 12.460, Predicted: 23.915\n",
      "Actual: 23.790, Predicted: 24.714\n",
      "Actual: 13.290, Predicted: 25.196\n",
      "Actual: 39.420, Predicted: 41.177\n",
      "Actual: 46.230, Predicted: 49.030\n",
      "Actual: 44.520, Predicted: 53.726\n",
      "Actual: 23.740, Predicted: 24.796\n",
      "Actual: 26.140, Predicted: 31.967\n",
      "Actual: 15.520, Predicted: 27.359\n",
      "Actual: 43.570, Predicted: 39.532\n",
      "Actual: 35.860, Predicted: 41.375\n",
      "Actual: 41.050, Predicted: 42.712\n",
      "Actual: 28.990, Predicted: 36.474\n",
      "Actual: 46.240, Predicted: 32.857\n",
      "Actual: 26.920, Predicted: 27.459\n",
      "Actual: 10.540, Predicted: 18.477\n",
      "Actual: 25.100, Predicted: 29.614\n",
      "Actual: 29.070, Predicted: 37.403\n",
      "Actual: 9.740, Predicted: 20.157\n",
      "Actual: 33.800, Predicted: 33.953\n",
      "Actual: 39.840, Predicted: 36.115\n",
      "Actual: 26.970, Predicted: 28.627\n",
      "Actual: 27.230, Predicted: 34.899\n",
      "Actual: 30.650, Predicted: 39.032\n",
      "Actual: 33.050, Predicted: 37.539\n",
      "Actual: 24.580, Predicted: 38.566\n",
      "Actual: 21.910, Predicted: 31.586\n",
      "Actual: 30.880, Predicted: 37.510\n",
      "Actual: 15.340, Predicted: 30.154\n",
      "Actual: 24.340, Predicted: 29.888\n",
      "Actual: 23.890, Predicted: 43.668\n",
      "Actual: 22.930, Predicted: 29.916\n",
      "Actual: 29.410, Predicted: 32.311\n",
      "Actual: 28.630, Predicted: 16.969\n",
      "Actual: 36.800, Predicted: 38.968\n",
      "Actual: 18.290, Predicted: 28.435\n",
      "Actual: 32.720, Predicted: 22.186\n",
      "Actual: 31.420, Predicted: 24.553\n",
      "Actual: 28.940, Predicted: 23.116\n",
      "Actual: 40.930, Predicted: 39.621\n",
      "Actual: 12.180, Predicted: 21.090\n",
      "Actual: 25.560, Predicted: 35.888\n",
      "Actual: 36.440, Predicted: 25.728\n",
      "Actual: 32.960, Predicted: 33.671\n",
      "Actual: 23.840, Predicted: 29.189\n",
      "Actual: 26.230, Predicted: 32.917\n",
      "Actual: 17.960, Predicted: 32.641\n",
      "Actual: 38.630, Predicted: 34.825\n",
      "Actual: 19.010, Predicted: 26.475\n",
      "Actual: 33.720, Predicted: 34.032\n",
      "Actual: 8.540, Predicted: 20.401\n",
      "Actual: 13.460, Predicted: 36.449\n",
      "Actual: 32.250, Predicted: 28.234\n",
      "Actual: 23.520, Predicted: 28.795\n",
      "Actual: 29.730, Predicted: 36.311\n",
      "Actual: 49.770, Predicted: 41.170\n",
      "Actual: 52.450, Predicted: 43.029\n",
      "Actual: 40.930, Predicted: 38.528\n",
      "Actual: 44.870, Predicted: 28.627\n",
      "Actual: 13.200, Predicted: 24.242\n",
      "Actual: 37.430, Predicted: 38.797\n",
      "Actual: 29.870, Predicted: 32.085\n",
      "Actual: 56.620, Predicted: 38.804\n",
      "Actual: 12.460, Predicted: 23.846\n",
      "Actual: 23.790, Predicted: 24.680\n",
      "Actual: 13.290, Predicted: 25.104\n",
      "Actual: 39.420, Predicted: 41.444\n",
      "Actual: 46.230, Predicted: 49.079\n",
      "Actual: 44.520, Predicted: 53.592\n",
      "Actual: 23.740, Predicted: 24.953\n",
      "Actual: 26.150, Predicted: 32.134\n",
      "Actual: 15.530, Predicted: 27.240\n",
      "Actual: 43.580, Predicted: 39.650\n",
      "Actual: 35.870, Predicted: 41.442\n",
      "Actual: 41.050, Predicted: 42.592\n",
      "Actual: 28.990, Predicted: 36.656\n",
      "Actual: 46.250, Predicted: 32.663\n",
      "Actual: 26.920, Predicted: 27.453\n",
      "Actual: 10.540, Predicted: 18.522\n",
      "Actual: 25.100, Predicted: 29.559\n",
      "Actual: 29.070, Predicted: 37.674\n",
      "Actual: 9.740, Predicted: 20.090\n",
      "Actual: 33.800, Predicted: 34.277\n",
      "Actual: 37.170, Predicted: 33.280\n",
      "Actual: 33.760, Predicted: 45.228\n",
      "Actual: 16.500, Predicted: 26.042\n",
      "Actual: 19.990, Predicted: 22.696\n",
      "Actual: 36.350, Predicted: 46.904\n",
      "Actual: 38.220, Predicted: 58.413\n",
      "Actual: 15.420, Predicted: 34.862\n",
      "Actual: 33.420, Predicted: 30.346\n",
      "Actual: 39.060, Predicted: 32.801\n",
      "Actual: 27.680, Predicted: 40.055\n",
      "Actual: 26.860, Predicted: 29.370\n",
      "Actual: 45.300, Predicted: 43.395\n",
      "Actual: 30.120, Predicted: 33.117\n",
      "Actual: 15.570, Predicted: 32.617\n",
      "Actual: 44.610, Predicted: 37.941\n",
      "Actual: 53.520, Predicted: 40.591\n",
      "Actual: 57.220, Predicted: 37.983\n",
      "Actual: 65.910, Predicted: 44.295\n",
      "Actual: 52.830, Predicted: 44.266\n",
      "Actual: 33.400, Predicted: 31.587\n",
      "Actual: 18.030, Predicted: 28.703\n",
      "Actual: 37.360, Predicted: 36.933\n",
      "Actual: 35.310, Predicted: 35.630\n",
      "Actual: 42.640, Predicted: 31.609\n",
      "Actual: 40.060, Predicted: 29.558\n",
      "Actual: 43.800, Predicted: 42.030\n",
      "Actual: 61.240, Predicted: 44.502\n",
      "Actual: 40.870, Predicted: 39.421\n",
      "Actual: 33.310, Predicted: 39.010\n",
      "Actual: 52.430, Predicted: 41.367\n",
      "Actual: 15.090, Predicted: 29.471\n",
      "Actual: 38.460, Predicted: 40.177\n",
      "Actual: 37.270, Predicted: 38.915\n",
      "Actual: 35.230, Predicted: 20.823\n",
      "Actual: 42.140, Predicted: 35.633\n",
      "Actual: 31.880, Predicted: 28.961\n",
      "Actual: 41.540, Predicted: 33.395\n",
      "Actual: 39.460, Predicted: 41.845\n",
      "Actual: 37.920, Predicted: 36.165\n",
      "Actual: 44.280, Predicted: 41.075\n",
      "Actual: 31.180, Predicted: 33.366\n",
      "Actual: 23.700, Predicted: 28.158\n",
      "Actual: 32.770, Predicted: 32.784\n",
      "Actual: 32.400, Predicted: 32.288\n"
     ]
    }
   ],
   "source": [
    "X, y = predictors_norm, target\n",
    "y_pred = model.predict(X)\n",
    "for actual, predicted in zip(y, y_pred):\n",
    "    print(f'Actual: {actual:.3f}, Predicted: {predicted[0]:.3f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
